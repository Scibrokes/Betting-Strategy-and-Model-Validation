---
title: "Betting Strategy and Ⓜodel Validation - Part II"
subtitle: "Betting Model Analysis on Sportsbook Consultancy Firm A"
author: "[®γσ, Eng Lian Hu](https://englianhu.github.io/) <img src='figure/ShirotoNorimichi2.jpg' width='24'> 白戸則道®"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html:
    toc: yes
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
bibliography: skeleton.bib
link-citations: yes
---

```{r libs, message = FALSE, warning = FALSE, cache = TRUE, include = FALSE}
## Setup Options, Loading Required Libraries and Preparing Environment
## Loading the packages and setting adjustment
suppressMessages(library('BBmisc'))
suppressAll(library('utils'))
suppressAll(source('function/libs.R'))
```

# Abstract

  This is an academic research by apply R statistics analysis to an agency A of an existing betting consultancy firm A. According to the *Dixon and Pope (2004)*^[Kindly refer to 24th paper in [Reference for industry knowdelege and academic research portion for the paper.] in **7.4 References**], due to business confidential and privacy I am also using agency A and firm A in this paper. **The purpose of the anaysis is measure the staking model of the firm A**. For more sample which using R for Soccer Betting see <http://rpubs.com/englianhu>. Here is the references of [rmarkdown](http://rmarkdown.rstudio.com/authoring_basics.html) and [An Introduction to R Markdown](http://rpubs.com/mansun_kuo/24330). You are welcome to read the *Tony Hirst (2014)*^[Kindly refer to 1st paper in [Reference for technical research on programming and coding portion for the paper.] in **7.4 References**] if you are getting interest to write a data analysis on Sports-book.

# [1. Introduction to the Betting Stategics](http://rstudio-pubs-static.s3.amazonaws.com/208637_3c45a2408ed94b9e8620b01714a4af41.html#introduction-to-the-betting-stategics)

  - Section [1.1 Introducing Betting Strategies](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#introducing-betting-strategies) - Introduce Betting Strategies
  - Section [1.2 Value Betting](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#value-betting) - Odds Price and Overrounds Changared by Bookmakers
  - Section [1.3 Professional Gambler](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#professional-gambler) - Punters' life and How Hedge Fund Works

# [2. Data](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#data)

  - Section [2.1 Collect and Reprocess the Data](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#collect-and-reprocess-the-data) - Data from Firm A
  - Section [2.2 Overrounds / Vigorish](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#overrounds-vigorish) - Odds Price and Overrounds Changared by Bookmakers

```{r read-data1, message = FALSE, warning = FALSE, echo = FALSE, results = 'asis'}
## Load saved dataset to save the loading time.
## directly load the dataset from running chunk `read-data-summary-table` and also chunk `scrap-data`. 
## The spboData for filtering leagues and matches scores purpose. Kindly refer to file named 
## `compacted data - shinyData.txt` inside folder `data`.

## Run above codes and save.images() and now directly load for shinyApp use.
load('./regressionApps/shinyData.RData', envir = .GlobalEnv)

## -------- chunk `bank-roll` -----------
## Re-categorise the soccer financial settlement date. Due to I have no the history matches dataset from bookmakers. The scrapped spbo time is not stable (always change, moreover there just an information website) where firm A is the firm who placed bets with millions HKD (although the kick-off time might also changed after placed that particular bet), therefore I follow the kick-off time of the firm A.
#'@ dat <- dat[order(dat$DateUK),] %>% mutate(DateUS = as.Date(format(DateUK, tz = 'EST', usetz = TRUE, format = '%Y-%m-%d %H:%M:%S'))) #daily settlement will base on variable `DateUS`.
```

# [3. Summarise the Staking Model](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#summarise-the-staking-model)

  - Section [3.1 Summarise Diversified Periodic Stakes](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#summarise-diversified-periodic-stakes) - Summarise the Stakes and Return
  - Section [3.2 Summarise the Staking Handicap](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#summarise-the-staking-handicap) - Summarise the Staking Handicap Breakdown
  - Section [3.3 Summarise the Staking Prices](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#summarise-the-staking-prices) - Summarise the Staking Price Range Breakdown
  - Section [3.4 Summarise the In-Play Staking Timing](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#summarise-the-in-play-staking-timing) - Summarise the In-Play Staking Breakdown by Time Range
  - Section [3.5 Summarise the In-Play Staking Based on Current Score](http://rstudio-pubs-static.s3.amazonaws.com/208637_8bb1bbc4930a4a22bf579a9b205eaea5.html#summarise-the-in-play-staking-based-on-current-score) - Summarise the In-Play Staking Breakdown by Current Score

# 4. Staking Ⓜodel

  - Section [4.1 Basic Equation] - Analyse the Odds Price and Probabilities
  - Section [4.2 Linear Ⓜodel] - Reversed Engineer to get the EMOdds derived from Stakes
  - Section [4.3 Kelly Ⓜodel] - Test the Kelly Model.
    + Section [4.3.1 Basic Kelly Ⓜodel] - Basic Kelly model.
    + Section [4.3.2 Weight Function] - Fractional Kelly model.
    + Section [4.3.3 Dynamic Kelly Ⓜodel] - Dynamic Kelly model.
  - Section [4.4 Poisson Ⓜodel] - Soccer Scores, Odds Price and Stakes modelling.
  - Section [4.5 Staking Ⓜodel and Ⓜoney Ⓜanagement] - Simulate the staking model.
  - Section [4.6 Expectation Ⓜaximization and Staking Simulation] - Enhance by weighted function on Staking model and Simulation.

## 4.1 Basic Equation

  Before we start modelling, we look at the summary of investment return rates.

```{r data-return-summary-table1, message = FALSE, warning = FALSE, echo = FALSE, results = 'asis'}
## Load package again due to cannot find the function
suppressMessages(library('lubridate'))
suppressMessages(library('tidyverse'))
suppressMessages(library('plyr'))
suppressMessages(library('dplyr'))
suppressMessages(library('magrittr'))
suppressMessages(library('formattable'))
suppressMessages(library('htmltools'))

## Get the investment return rates per annun
## http://www.math.ku.dk/~rolf/teaching/thesis/DixonColes.pdf
## value rRates is based on annual EMProb/netProb ratio, while EMProb get from equation 4.1.2
m <- ddply(dat, .(Sess), summarise, Stakes = sum(Stakes), PL = sum(PL), n = length(Sess), rRates = PL / Stakes) %>% mutate(Stakes = currency(Stakes), PL = currency(PL), n = accounting(n, format = 'd'), rRates = percent(rRates)) %>% tbl_df

tagList(
  tags$div(align = "center", 
           class = "bg-info", 
           tags$h3(class = "bg-primary", "Profit and Loss of Investment"), 
           tags$h5(align = "center", class = "text-muted", 
                   "Annual Stakes and Profit and Loss of Firm A at Agency A (2011-2015) ($0,000)")), 
  as.htmlwidget(m %>% formattable(list(
    
    Stakes = color_tile('white', 'darkgoldenrod'), 
    
    PL = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'green', 'gray')), x ~ paste0(round(x, 2), ' (rank: ', sprintf('%02d', rank(-x)), ')')), 
    
    n = color_tile('white', '#9B870C'), 
    
    rRates = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'green', 'gray')), x ~ sprintf('%1.2f%% (rank: %02d)', 100 * x, rank(-x)))))))
```

*table 4.1.1* : `r paste0(dim(m), collapse = ' x ')` : *Return of annually investment summary table.*^[Kindly refer to the list of colors via [Dark yellow with hexadecimal color code #9B870C](http://encycolorpedia.com/9b870c) for plot the stylist table.]

$$\Re = \sum_{i=1}^{n}\rho_{i}^{EM}/\sum_{i=1}^{n}\rho_{i}^{BK} \cdots equation\ 4.1.1$$

  $\Re$ is the edge or so call advantage for an investment. The $\rho_i^{EM}$ is the estimated probabilities which is the calculated by firm A from match 1,2... until $n$ matches while $\rho_{i}^{BK}$ is the net/pure probability (real odds) offer by bookmakers after we fit the *equation 4.1.2* into *equation 4.1.1*.

$$\rho_i = P_i^{Lay} / (P_i^{Back} + P_i^{Lay}) \cdots equation\ 4.1.2$$

$P_i^{Back}$ and $P_i^{Lay}$ is the backed and layed fair price offer by bookmakers.

  We can simply apply equation above to get the value $\Re$. From the table above we know that the EMPrice calculated by firm A **invested** at a threshold edge (price greater) `r m$rRates` than the prices offer by bookmakers. There are some description about $\Re$ on *Dixon and Coles (1996)*^[Kindly refer to 25th paper in [Reference for industry knowdelege and academic research portion for the paper.] under **7.4 References**]. The optimal value of $\rho_{i}$ (`rEMProbB`) will be calculated based on bootstrapping/resampling method in section [4.3 Kelly Ⓜodel].

  Now we look at the result of the soccer matches prior to filter out for further modelling from this section.

```{r data-return-summary-table2, echo = FALSE, results = 'asis'}
## http://www.statmethods.net/stats/frequencies.html
## prop.table, margin.table
## margin.table(table(dat$Result), 1)
##
## library('gmodels')
## CrossTable(dat$HCap, dat$Result)
##
suppressMessages(library('dplyr'))
suppressMessages(library('formattable'))
suppressMessages(library('htmltools'))

m1 <- ddply(dat, .(Result), summarise, Stakes = sum(Stakes), Return = sum(Return), Rates = Return / Stakes, n = length(Sess)) %>% tbl_df %>% mutate(S.prop = round(Stakes / sum(Stakes), 4), R.prop = round(Return / sum(Return), 4), prop = round(n / sum(n), 4))
tv <- c('Total', colSums(m1[-1])); tv[4] <- as.numeric(tv[3]) / as.numeric(tv[2])
m1 <- suppressWarnings(rbind(m1, tv))
m1$Result <- factor(c(as.character(m1$Result)[-length(m1$Result)], 'Total')); rm(tv)
m1 %<>% purrr::map_if(is.character, as.numeric) %>% data.frame %>% tbl_df %>% mutate(Stakes = currency(Stakes), Return = currency(Return), Rates = percent(Rates), n = accounting(n, format = 'd'), S.prop = percent(S.prop), R.prop = percent(R.prop), prop = percent(prop))
#'@ m %>% kable(caption = 'Table 4.1.3 : Summary of Betting Results')

tagList(
  tags$div(align = "center", 
           class = "bg-info", 
           tags$h3(class = "bg-primary", "Profit and Loss of Investment"), 
           tags$h5(align = "center", class = "text-muted", 
                   "Stakes and Profit and Loss of Firm A at Agency A (2011~2015) ($0,000)")), 
  as.htmlwidget(m1 %>% formattable(list(
    
    #'@ Stakes = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ sprintf('%.2f (rank: %.0f)', x, rank(-x))),
    Stakes = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ paste0(round(x, 2), ' (rank: ', sprintf('%02d', rank(-x)), ')')), 
    
    #'@ Return = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ sprintf('%.2f (rank: %.0f)', x, rank(-x))),
    Return = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ paste0(round(x, 2), ' (rank: ', sprintf('%02d', rank(-x)), ')')), 
    
    Rates = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ sprintf('%1.2f%% (rank: %.0f)', 100 * x, rank(-x))),
    
    n = color_tile('white', 'green'),
    
    S.prop = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ sprintf('%1.2f%% (rank: %2d)', 100 * x, rank(-x))),
    
    R.prop = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ sprintf('%1.2f%% (rank: %.0f)', 100 * x, rank(-x))),
    
    prop = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ sprintf('%1.2f%% (rank: %.0f)', 100 * x, rank(-x)))
))))
```

*table 4.1.2* : `r paste0(dim(m1), collapse = ' x ')` : *Summary of betting results.*

  The table above summarize the stakes and return on soccer matches result. <s> Well, below table list the handicaps placed by firm A on agency A. Due to the **Cancelled** result is null observation in descrete data modelling and we cannot be count into our model. Here Ifilter out the particular observation from the data from here and now the total observation of the dataset became `r nrow(dat)`.
</s>

**CORRECTION :** need to keep the cancelled matches as the "push" to count in the probability of the cancellation betslip as well which is occurred in real life.

```{r filtered-data, eval = FALSE, echo = FALSE, results = 'asis'}
## Filtered the cancelled or voided bets to avoid null observation and bias.
## 
## CORRECTION : need to keep the cancelled matches as the "push" to count in the probability of the cancellation betslip as well which is occurred in real life.

if('Cancelled' %in% dat$Result){
  dat %<>% filter(Result != 'Cancelled') %>% mutate(Result = factor(Result))
} else dat %<>% mutate(Result = factor(Result))
```

```{r data-prob-table2, echo = FALSE, results = 'asis'}
## http://www.math.ku.dk/~rolf/teaching/thesis/DixonColes.pdf
## value R.rates is based on annual EMProb/netProb ratio, while EMProb get from equation 4.1.2
## Please refer to function arrfirmDatasets()
#'@ dat %<>% mutate(rEMProbB = round(unlist(lapply(split(dat, dat$Sess), function(x) rep(m$rRates, nrow(x)))) * netProbB, 6), rEMProbL = round(1 - rEMProbB, 6))

# Kelly criterion
# Advantages = (prob of win * decimal odds) + (prob of lose * -1)
# Optimal Kelly wager % = Advantages / decimal odds

#'@ dat$rRates <- rep(m$rRates, count(dat, Sess)$n) #unable found 'Sess' when knit but workable when run chunk-by-chunk.
dat$rRates <- rep(as.numeric(m$rRates + 1), ddply(dat, .(Sess), summarise, n = length(Sess))$n)
dat$rEMProbB <- round(dat$rRates * dat$netProbB, 6)
dat$rEMProbL <- round(1 - dat$rEMProbB, 6)
dat$netEMEdge <- round(dat$rEMProbB / dat$netProbB, 6)

dat %>% select(No.x, EUPrice, HKPrice, fHKPriceL, fMYPriceB, fMYPriceL, netProbB, netProbL, rRates, rEMProbB, rEMProbL, netEMEdge, favNetProb, undNetProb) %>% .[sample(1:nrow(.), 6), ] %>% formattable %>% as.htmlwidget
```

*table 4.1.3* : `r paste0(dim(dat), collapse = ' x ')` : *Odds price and probabilities sample table.*

  Above table list a part of sample odds prices and probabilities of soccer match $i$ while $n$ indicates the number of soccer matches. We can know the values `rEMProbB`, `netProbB` and so forth.

```{r data-prob-plot2, eval = FALSE, message = FALSE, warning = FALSE, echo = FALSE, results = 'asis'}
## Linear model
## Learn about API authentication here: https://plot.ly/r/getting-started
## Find your api_key here: https://plot.ly/settings/api

#'@ model <- lm(rEMProbB ~ netProbB, data=dat)
#'@ grid <- with(dat, expand.grid(netProbB = seq(min(netProbB), max(netProbB), length = 20),
#'@                                 rEMProbB = seq(min(rEMProbB), max(rEMProbB), length = 20)))
#'@ grid$rEMProb <- stats::predict(model, newdata=grid)
#'@ viz2 <- qplot(netProbB, rEMProbB, data=dat) + geom_point(data=grid)
#'@ out <- ggplotly(viz2)
#'@ plotly_url <- out$response$url

#'@ ggplot(dat, aes(x = netProbB, y = rEMProbB)) + geom_point(aes(y = netProbB, color = 'netProbB')) + geom_point(aes(y = rEMProbB, color = 'rEMProbB')) + xlab('Bookmaker Backed Net Prob') + ylab('Calculated EM Backed Prob') + theme_economist(base_family='Verdana') + scale_colour_economist() + ggtitle('Bookmaker Net Probabilities -vs- Firm A EM Probabilities')

gvis.options <- list(title = "Bookmaker Net Probabilities -vs- Firm A EM Probabilities", series = "[{targetAxisIndex:0},{targetAxisIndex:1}]", hAxis = "{title:'Bookmaker Backed Net Prob'}", vAxis = "{title:'rEMProbB'},{title:'netProbB'}", pointSize = 2, width = 'automatic', height = 'automatic', gvis.editor = 'Edit me!', gvis.plot.tag = 'chart')

#'@ plot4.1.1 <- gvisLineChart(xvar = 'netProbB', yvar = 'rEMProbB', data = dat, options = gvis.options)
plot4.1.1 <- googleVis::gvisScatterChart(dat[c('netProbB', 'rEMProbB')], options = gvis.options)
plot(plot4.1.1)

rm(plot4.1.1)
```

```{r data-prob-plot2b, message = FALSE, warning = FALSE, echo = FALSE, results = 'asis'}
## Due to gvisScatterChart inside `data-prob-plot2` keep plot javascript output, here I use alternate `highcharter` package to plot the graph.

## Load package again due to unable found the function.
suppressMessages(library('highcharter'))

hchart(dat[c('netProbB', 'rEMProbB', 'pMYRange')], 'scatter', x = netProbB, y = rEMProbB, group = pMYRange)
```

*graph 4.1.1* : *A sample graph about the relationship between the investmental probabilities -vs- bookmakers' probabilities.*

  Graph above shows the probabilities calculated by firm A to back against real probabilities offered by bookmakers over `r nrow(dat)` soccer matches.

  I list the handicap below prior to test the coefficient according to the handicap in next section [4.2 Linear Ⓜodel].

```{r data-preMatch, echo = FALSE, results = 'asis'}
##
## Calculate the proportional model on the results, which are 'Cancelled', 'Half-Loss', 'Half-Win', 'Loss', 'Push', 'Win'.
## Ommited the InPlay matches, filter out the sample data, only Pre-Games matches taken into further calculations.
preData <- filter(dat, InPlay == 'No' & InPlay2 == 'No')
hdp <- sort(unique(as.numeric(as.character(dat$HCap))))

hdp %<>% matrix(., nrow = 8) %>% data.frame %>% tbl_df

hdp %>% formattable(list(
  X1 = formatter('span', style = x ~ style(color = ifelse(x > 0, 'green', 'red')), x ~ icontext(ifelse(x > 0, x, -x), ifelse(x, x, x))), 
  X2 = formatter('span', style = x ~ style(color = ifelse(x > 0, 'green', 'red')), x ~ icontext(ifelse(x > 0, x, -x), ifelse(x, x, x))), 
  X3 = formatter('span', style = x ~ style(color = ifelse(x > 0, 'green', 'red')), x ~ icontext(ifelse(x > 0, x, -x), ifelse(x, x, x))), 
  X4 = formatter('span', style = x ~ style(color = ifelse(x > 0, 'green', 'red')), x ~ icontext(ifelse(x > 0, x, -x), ifelse(x, x, x))), 
  X5 = formatter('span', style = x ~ style(color = ifelse(x > 0, 'green', 'red')), x ~ icontext(ifelse(x > 0, x, -x), ifelse(x, x, x))), 
  X6 = formatter('span', style = x ~ style(color = ifelse(x > 0, 'green', 'red')), x ~ icontext(ifelse(x > 0, x, -x), ifelse(x, x, x))) 
  )
) %>% as.htmlwidget
```

*table 4.1.4 : `r paste0(dim(hdp), collapse = ' x ')` : The handicap in sample data.*

## 4.2 Linear Ⓜodel

  From our understanding of staking, the covariates we need to consider should be only odds price since the handicap's covariate has settled according to different handicap of EMOdds.

```{r plot4.2.1, echo = FALSE, eval = FALSE, results = 'asis'}
## Due to rCharts unable print the graph on rmarkdown file but works independently, here I ommit the rPlot.

n1 <- rPlot(Return ~ Stakes, data = dat, color = 'Stakes', type = 'point')
n1$addControls('x', value = 'Stakes', values = names(dat))
n1$addControls('y', value = 'Stakes', values = names(dat))
n1$addControls('color', value = 'Stakes', values = names(dat))
#'@ n1$print(include_assets = TRUE)
#'@ 
n1
```

  Again, I don't pretend to know the correct Ⓜodel, here I simply apply linear model to retrieve the value of *EMOdds* derived from stakes. The purpose of measure the edge overcame bookmakers' vigorish is *to know the levarage of the staking activities onto 1 unit edge of odds price by firm A to agency A*. By refer to *figure 4.4.1*, I includes the models which split the pre-match and in-play ito comparison.

```{r linear-models, echo = FALSE, results = 'asis'}
## Choosing the variables of linear models
## The net probabilities might open diversified handicap, therefore the HCap parameter need to be insert as one of parameter since the return of draw-no-bet, win-half, win-full, loss-half, loss-full (example : 0, 0/0.5, 0.5, 0.5/1, 1) affect the return of investment.
## lm0 indicate matches include prematch and inplay. lm0pm is subsetted with only prematch while lmip subsetted which only inplay matches.

lm0 <- lm(Return ~ Stakes, data = dat)
lm0pm <- lm(Return ~ Stakes, data = dat, subset = c(InPlay == 'No' & InPlay2 == 'No'))
lm0ip <- lm(Return ~ Stakes, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm1 <- lm(Return ~ Stakes + HCap, data = dat)
lm1pm <- lm(Return ~ Stakes + HCap, data = dat, subset = c(InPlay == 'No' & InPlay2 == 'No'))
lm1ip <- lm(Return ~ Stakes + HCap, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm2 <- lm(Return ~ Stakes + netProbB, data = dat)
lm2pm <- lm(Return ~ Stakes + netProbB, data = dat, subset = c(InPlay == 'No' & InPlay2 == 'No'))
lm2ip <- lm(Return ~ Stakes + netProbB, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm3 <- lm(Return ~ Stakes + HCap + netProbB, data = dat)
lm3pm <- lm(Return ~ Stakes + HCap + netProbB, data = dat, subset = c(InPlay == 'No' & InPlay2 == 'No'))
lm3ip <- lm(Return ~ Stakes + HCap + netProbB, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm4 <- lm(Return ~ Stakes + ipRange, data = dat)
lm4ip <- lm(Return ~ Stakes + ipRange, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm5 <- lm(Return ~ Stakes + ipHCap, data = dat)
lm5ip <- lm(Return ~ Stakes + ipHCap, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm6 <- lm(Return ~ Stakes + HCap + ipRange, data = dat)
lm6ip <- lm(Return ~ Stakes + HCap + ipRange, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm7 <- lm(Return ~ Stakes + CurScore + ipHCap, data = dat)
lm7ip <- lm(Return ~ Stakes + CurScore + ipHCap, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm8 <- lm(Return ~ Stakes + CurScore + ipRange, data = dat)
lm8ip <- lm(Return ~ Stakes + CurScore + ipRange, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm9 <- lm(Return ~ Stakes + CurScore + ipRange + ipHCap, data = dat)
lm9ip <- lm(Return ~ Stakes + CurScore + ipRange + ipHCap, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

## Linear Interative Effect Models
lm10 <- lm(Return ~ HCap + netProbB + HCap:netProbB, data = dat)
lm10pm <- lm(Return ~ HCap + netProbB + HCap:netProbB, data = dat, subset = c(InPlay == 'No' & InPlay2 == 'No'))
lm10ip <- lm(Return ~ HCap + netProbB + HCap:netProbB, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm11 <- lm(Return ~ Stakes + ipHCap + ipRange + ipHCap:ipRange, data = dat)
lm11ip <- lm(Return ~ Stakes + ipHCap + ipRange + ipHCap:ipRange, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm12 <- lm(Return ~ Stakes + CurScore + ipRange + ipHCap + CurScore:ipHCap:ipRange, data = dat)
lm12ip <- lm(Return ~ Stakes + CurScore + ipRange + ipHCap + CurScore:ipHCap:ipRange, data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

## Linear Mixed Effects Models
## Mixed effect categorised the parameters by group... similar with current score during living betting modelling, the scoring rate (intensity of scores) during 0-0 is different with scoring rates during 1-0 etc.
lm13 <- lm(Return ~ Stakes + (1|HCap), data = dat)
lm13pm <- lm(Return ~ Stakes + (1|HCap), data = dat, subset = c(InPlay == 'No' & InPlay2 == 'No'))
lm13ip <- lm(Return ~ Stakes + (1|HCap), data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lm14 <- lm(Return ~ HCap + (1|Stakes), data = dat) # the stakes amount placed by firm A must be based on the degree of the edges to punter. Here I try to test the effect. (Although firm A might bet via several agents, here I can only took available sample from population to test the efficiency.)
lm14pm <- lm(Return ~ HCap + (1|Stakes), data = dat, subset = c(InPlay == 'No' & InPlay2 == 'No'))
lm14ip <- lm(Return ~ HCap + (1|Stakes), data = dat, subset = c(InPlay != 'No' & InPlay2 != 'No'))

lms <- list(lm0 = lm0, lm0pm = lm0pm, lm0ip = lm0ip, lm1 = lm1, lm1pm = lm1pm, lm1ip = lm1ip, lm2 = lm2, lm2pm = lm2pm, lm2ip = lm2ip, lm3 = lm3, lm3pm = lm3pm, lm3ip = lm3ip, lm4 = lm4, lm4ip = lm4ip, lm5 = lm5, lm5ip = lm5ip, lm6 = lm6, lm6ip = lm6ip, lm7 = lm7, lm7ip = lm7ip, lm8 = lm8, lm8ip = lm8ip, lm9 = lm9, lm9ip = lm9ip, lm10 = lm10, lm10pm = lm10pm, lm10ip = lm10ip, lm11 = lm11, lm11ip = lm11ip, lm12 = lm12, lm12ip = lm12ip, lm13 = lm13, lm13pm = lm13pm, lm13ip = lm13ip, lm14 = lm14, lm14pm = lm14pm, lm14ip = lm14ip)

rm(lm0, lm0pm, lm0ip, lm1, lm1pm, lm1ip, lm2, lm2pm, lm2ip, lm3, lm3pm, lm3ip, lm4, lm4ip, lm5, lm5ip, lm6, lm6ip, lm7, lm7ip, lm8, lm8ip, lm9, lm9ip, lm10, lm10pm, lm10ip, lm11, lm11ip, lm12, lm12ip, lm13, lm13pm, lm13ip, lm14, lm14pm, lm14ip)
```

<s>
```{r lm-summary, echo = FALSE, eval = FALSE, results = 'asis'}
## There has a package htmlTable as well, you can compare among xtable, stargazer, htmlTable, formattable and knit::kable().
## https://cran.r-project.org/web/packages/htmlTable/vignettes/tables.html

## Kindly refer to below *shinyapp 4.2.1* as I wrote as an shiny app.

#'@ anova to compare the models
#'@ anova(lm0, lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8, lm9, lm10, lm11, lm12, lm13, lm14, test = 'F')

## xtable always shows LaTeX output but not table.
#'@ list(lm0, lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8, lm9, lm10, lm11, lm12, lm13, lm14) %>% llply(., function(x) print(xtable(x), floating = TRUE, type = 'html'))

#'@ list(lm0, lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8, lm9, lm10, lm11, lm12, lm13, lm14) %>% llply(., stargazer, type = 'html')
stargazer(lm0, lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8, lm9, lm10, lm11, lm12, lm13, lm14, type = 'html')

#'@ list(lm0, lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8, lm9, lm10, lm11, lm12, lm13, lm14) %>% llply(., texreg)
```

```{r lm-anova, echo = FALSE, eval = FALSE, results = 'asis'}
## Kindly refer to below *shinyapp 4.2.1* as I wrote as an shiny app.

## xtable always shows LaTeX output but not table.
#'@ list(lm0, lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8, lm9, lm10, lm11, lm12, lm13, lm14) %>% llply(., function(x) print(xtable(anova(x)), floating = TRUE, type = 'html'))

#'@ list(lm0, lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8, lm9, lm10, lm11, lm12, lm13, lm14) %>% llply(., function(x) stargazer(anova(x), type = 'html'))

#'@ stargazer(anova(lm0, lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8, lm9, lm10, lm11, lm12 lm13, lm14), type = 'html')

stargazer(anova(lm0, lm1, lm2, lm3, lm4), type = 'html')
#'@ list(lm5, lm6, lm7, lm8, lm9, lm10, lm11, lm12) %>% llply(stargazer, anova, type = 'html')
stargazer(anova(lm5), type = 'html')
stargazer(anova(lm6), type = 'html')
stargazer(anova(lm7), type = 'html')
stargazer(anova(lm8), type = 'html')
stargazer(anova(lm9), type = 'html')
stargazer(anova(lm10), type = 'html')
stargazer(anova(lm11), type = 'html')
stargazer(anova(lm12), type = 'html')
stargazer(anova(lm13), type = 'html')
stargazer(anova(lm14), type = 'html')

#'@ list(lm0, lm1, lm2, lm3, lm4, lm5, lm6, lm7, lm8, lm9, lm10, lm11, lm12, lm13, lm14) %>% llply(., function(x) texreg(anova(x)))
```
</s>

  When I used to work in 188Bet and Singbet as well as AS3388, we know from the experience which is the odds price of favorite team win will be the standard reference and the draw odds will adjust a little bit while the underdog team will be ignore.

  *Steven Xu (2013)*^[Kindly refer to 16th paper in [Reference for industry knowdelege and academic research portion for the paper.]] has do a case study on the comparison of the efficiency of opening and closing price of NFL and College American Football Leagues and get to know the closing price is more efficient and accurate compare to opening price nowadays compare to years 1980~1990. It might be due to multi-million dollars of stakes from informed traders or smart punters to tune up the closing price to be likelihood.

  In order to test the empirical clichés, I used to conduct a research thoroughly through *®γσ, Eng Lian Hu (2016)*^[Kindly refer to 3rd paper in [Reference for industry knowdelege and academic research portion for the paper.] under **7.4 References**, I completed the research on year 2010 but write the thesis in year 2016.] and concludes that the opening price of Asian Handicap and also Goal Lines of 29 bookmakers are efficient than mine. However in my later *®γσ, Eng Lian Hu (2014)*^[Kindly refer to 4th paper in [Reference for industry knowdelege and academic research portion for the paper.] under **7.4 References**] applied Kelly staking model where made a return of more than 30% per sesson. Meanwhile, the *Dixon and Coles (1996)* and *Crowder, Dixon, Ledford and Robinson (2001)*^[Kindly refer to 27th paper in [Reference for industry knowdelege and academic research portion for the paper.] under **7.4 References**] has built two models which compare the accuracy of home win, draw and away win. From a normal Poison model reported the home win is more accurate and therefore an add-hoc inflated parameter required in order to increase the accuracy of prediction. You are feel free to learn about the *Dixon and Coles (1996)* in section [4.4 Poisson Ⓜodel].

  Based on *table 2.2.1* we know about the net bookies probabilities and EM probabilities, here I simply apply *linear regression model*^[You can learn from [Linear Regression in R (R Tutorial 5.1 to 5.11)](https://www.youtube.com/watch?v=66z_MRwtFJM). You can also refer to [Getting Started with Mixed Effect Models in R](http://www.r-bloggers.com/getting-started-with-mixed-effect-models-in-r/), [A very basic tutorial for performing linear mixed effects analyses](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/A%20Very%20Basic%20Tutorial%20for%20Performing%20Linear%20Mixed%20Effects%20Analyses.pdf) and [Fitting Linear Mixed-Effects Models using lme4](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Fitting%20Linear%20Mixed-Effects%20Models%20Using%20lme4.pdf). Otherwise you can read [Linear Models with R](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Linear%20Models%20with%20R.pdf) and somemore details about regression models via [Extending the Linear Model with R : Generalized Linear, Mixed Effects and Nonparametric Regression Models](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Extending%20the%20Linear%20Model%20with%20R%20-%20Generalized%20Linear%2C%20Mixed%20Effects%20and%20Nonparametric%20Regression%20Models.pdf). Besides, [What statistical analysis should I use?](http://www.ats.ucla.edu/stat/mult_pkg/whatstat/) summarise a table for test analysis and data validation. [Fit models to data](https://www.zoology.ubc.ca/~schluter/R/fit-model/) provides examples for application of linear regression and model selection, the main model-fitting commands covered *lm (linear models for fixed effects)*, *lme (linear models for mixed effects)*, *glm (generalized linear models)*, *nls (nonlinear least squares)*, *gam (generalized additive models)* and also *visreg (to visualize model fits)*. The answer from [How to use R anova() results to select best model?](http://stats.stackexchange.com/questions/172782/how-to-use-r-anova-results-to-select-best-model) eleborates the use of ANOVA and [AIC criterion](https://en.wikipedia.org/wiki/Akaike_information_criterion) to choose the best fit model. [How to Choose the Best Regression Model](http://blog.minitab.com/blog/adventures-in-statistics/how-to-choose-the-best-regression-model) describes how to find the best regresion model to fit and applicable to the real world. [ANOVA - Model Selection](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/ANOVA%20-%20Model%20Selection.pdf) summarised a lecture notes in slideshow while [Model Selection in R](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Model%20Selection%20in%20R.pdf) conducts a research on model selection for non-nested linear and polynomial models.] and also anova to compare among the models.

![*shinyapp 4.2.1 : WDW-AH convertion and summary and anova of linear models.* Kindly click on [*regressionApps*](https://beta.rstudioconnect.com/content/1807)^[You might select Y response variable and X explanatory variable(s) to measure your model (Refer to [Shiny height-weight example](runGist("https://gist.github.com/wch/4034323")) for further information about shinyapp for linear models.) or existing models.] to use the ShinyApp.](figure/20160928_021252.gif)

  Here I simply attached with a Fixed Odds to Asian Handicap's calculator which refer to my *ex-colleague William Chen's*^[My ex-colleague and best friend in sportsbook industry which known since join sportsbook industry year 2005 ------ Telebiz and later Caspo Inc.] spreadsheet version 1.1 in year 2006. You can simply input the home win, draw, away win (in decimal format) as well as the overround to get the conversion result from the simple an basic equation.^[Kindly refer to my previous research to know the vigorish / overround.]

  From the summary of *shinyapp 4.2.1*, we know the comparison among the models to get the best fitted model.

```{r compare, echo = FALSE, results = 'asis'}
suppressMessages(library('stringr'))

compare <- ldply(lms, function(x) {
    y <- summary(x)$fstatistic
    df <- data.frame(AIC = AIC(x), BIC = BIC(x), t(summary(x)$df), 'p.value' = pf(y[1], y[2], y[3], lower.tail = FALSE))
    names(df) <- c('AIC', 'BIC', 'df', 'residuals', 'df', 'p.value'); df}) %>% data.frame(No = seq(nrow(.)), Cat = ifelse(str_detect(.$.id, 'pm'), 'pm', ifelse(str_detect(.$.id, 'ip'), 'ip', 'all')), .) %>% tbl_df

compare %<>% mutate(delta.AIC = AIC - min(AIC), Loglik.AIC = exp(-0.5 * delta.AIC), weight.AIC = Loglik.AIC/sum(Loglik.AIC), delta.BIC = BIC - min(BIC), Loglik.BIC = exp(-0.5 * delta.BIC), weight.BIC = Loglik.BIC/sum(Loglik.BIC))

form <- ldply(lms, function(x) paste0(x$call[-1], collapse = ' , '))# %>% rename(.id = .id, formula = V1)
names(form) <- c('.id', 'formula')

## Skip below combination to avoid hard to read since long formula column will make data.frame looks weird.
#'@ compare %<>% join(form, ., by = '.id') %>% select(No, Cat, .id, formula, AIC, BIC, df, residuals, p.value, delta.AIC, Loglik.AIC, weight.AIC, delta.BIC, Loglik.BIC, weight.BIC)

## Refer to *figure 4.4.1* to compare the models, between "all" and "pm + ip".
bestlm <- compare %>% filter(p.value < 0.05) %>% group_by(Cat) %>% slice(which.min(BIC)) %>% mutate(AIC = accounting(AIC), BIC = accounting(BIC), df = accounting(df, format = 'd'), residuals = accounting(residuals, format = 'd'), p.value = percent(p.value), delta.AIC = accounting(delta.AIC), delta.BIC = accounting(delta.BIC)) #best model for every single category.

compare %<>% mutate(AIC = accounting(AIC), BIC = accounting(BIC), df = accounting(df, format = 'd'), residuals = accounting(residuals, format = 'd'), p.value = percent(p.value), delta.AIC = accounting(delta.AIC), delta.BIC = accounting(delta.BIC)) %>% split(., .$Cat) #split the category and list the ranking.

form %>% formattable %>% as.htmlwidget
```

*table 4.2.1 : Application of linear regression models to test the effects on staking.*

```{r compare-A, echo = FALSE, results = 'asis'}
## all soccer matches
compare[[1]] %>% formattable(list(
  AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %.0f)', x, rank(x))),

  BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %.0f)', x, rank(x))),
  
  df = formatter('span', style = x ~ formattable::style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %02d)', x, rank(-x))),
  
  residuals = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %02d)', x, rank(x))),
  
  p.value = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%1.2f%% (rank: %02d)', 100 * x, rank(x))),
  
  delta.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  Loglik.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  weight.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  delta.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  Loglik.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  weight.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x)))

  )) %>% as.htmlwidget
```

*table 4.2.2A : Best model to test the effects of staking on all soccer matches (includes both pre-match and in-play).*

```{r compare-B, echo = FALSE, results = 'asis'}
## all soccer matches
compare[[3]] %>% formattable(list(
  AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %.0f)', x, rank(x))),
  
  BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %.0f)', x, rank(x))),
  
  df = formatter('span', style = x ~ formattable::style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %02d)', x, rank(-x))),
  
  residuals = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %02d)', x, rank(x))),
  
  p.value = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%1.2f%% (rank: %02d)', 100 * x, rank(x))),
  
  delta.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  Loglik.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  weight.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  delta.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  Loglik.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  weight.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x)))

  )) %>% as.htmlwidget
```

*table 4.2.2B : Best model to test the effects of staking on pre-match soccer matches.*

```{r compare-C, echo = FALSE, results = 'asis'}
## all soccer matches
compare[[2]] %>% formattable(list(
  AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %.0f)', x, rank(x))),
  
  BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %.0f)', x, rank(x))),
  
  df = formatter('span', style = x ~ formattable::style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %02d)', x, rank(-x))),
  
  residuals = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %02d)', x, rank(x))),
  
  p.value = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%1.2f%% (rank: %02d)', 100 * x, rank(x))),
  
  delta.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  Loglik.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  weight.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  delta.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  Loglik.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  weight.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x)))

  )) %>% as.htmlwidget
```

*table 4.2.2C : Best model to test the effects of staking on in-play soccer matches.*

```{r compare2, echo = FALSE, results = 'asis'}
## summary of the best model

bestlm %>% formattable(list(
  AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %.0f)', x, rank(x))),
  
  BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %.0f)', x, rank(x))),
  
  df = formatter('span', style = x ~ formattable::style(color = ifelse(rank(-x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %.0f)', x, rank(-x))),
  
  residuals = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.0f (rank: %.0f)', x, rank(x))),
  
  p.value = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%1.2f%% (rank: %02d)', 100 * x, rank(x))),
  
  delta.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  Loglik.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  weight.AIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  delta.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  Loglik.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x))),
  
  weight.BIC = formatter('span', style = x ~ formattable::style(color = ifelse(rank(x) <= 3, 'blue', 'grey')), x ~ sprintf('%.4f (rank: %.0f)', x, rank(x)))

  )) %>% as.htmlwidget
```

*table 4.2.3 : Best model to test the effects of staking soccer matches.*

  Base on above few tables and also summarised *table 4.2.3*, we can compare both `r dplyr::filter(bestlm, Cat == 'all') %>% .$'.id'` and `r dplyr::filter(bestlm, Cat != 'all') %>% .$'.id' %>% paste0(., collapse = ' + ')` and decide that the model *`r bestm = ifelse(bestlm$BIC[1] > sum(bestlm$BIC[-1]), dplyr::filter(bestlm, Cat != 'all') %>% .$'.id' %>% paste0(., collapse = ' + '), ifelse(bestlm$AIC[1] > sum(bestlm$AIC[-1]), dplyr::filter(bestlm, Cat != 'all') %>% .$'.id' %>% paste0(., collapse = ' + '), dplyr::filter(bestlm, Cat == 'all') %>% .$'.id')); bestm`*^[BIC will be primary reference while AIC is the secondary reference. The smallest value is the best model. `r paste0('all = ', bestlm$BIC[1], ' and mixed = ', sum(bestlm$BIC[-1]))`] is the best fit to determine the factors and effects to place stakes for all matches^[mixed InPlay + Pre-match, all observations are `r nrow(dat)` soccer matches which has placed bets.]. The timing of InPlay and the stakes amount is the major effects to the return of investment.

  *John Fingleton & Patrick Waldron (1999)* apply Shin's model and finally conclude suggests that bookmakers in Ireland are infinitely risk-averse and balance their books. The authors cannot distinguish between inside information and operating costs, merely concluding that combined they account for up to 3.7% of turnover while normally Asian bookmakers made less than 1% and a anonymous company has made around 2%. However the revenue or the stakes are farly more than European bookmakers.^[You can refer to my another project [Analyse the Finance and Stocks Price of Bookmakers](https://github.com/scibrokes/analyse-the-finance-and-stocks-price-of-bookmakers) which analysis the financial report of public listed companies and also profitable products' revenue and profit & loss of anonymous company.]. 
  
  They compare different versions of our model, using data from races in Ireland in 1993. The authors' empirical results can be summarised as follows:
  
  - They reject the hypothesis that bookmakers behave in a risk neutral manner;
  - They cannot reject the hypothesis that they are infinitely riskaverse;
  - They estimate gross margins to be up to 4 per cent of total oncourse turnover; and
  - They estimate that 3.1 to 3.7% (by value) of all bets are placed by punters with inside information.

![*figure 4.2.1 : Chance of Winning.*](figure/chance-of-winning.jpg)

  Due to the Shin model inside the paper research for the sake of bookmakers and this sportsbook consultancy firm is indeed the informed trading (means smart punters or actuarial hedge fund but not ordinary gambler place bets with luck). Here I think of test our previous data in paper *®γσ, Eng Lian Hu (2016)*^[Kindly refer to 3rd paper in [Reference for industry knowdelege and academic research portion for the paper.] under **7.4 References** which collect the dataset of opening and also closing odds price of 40 bookmakers and 29 among them with Asian Handicap and Goal Line. Meanwhile, there has another research on smart punters (*Punters Account Review (Agenda).xlsx*) which make million dollars profit from Ladbrokes. You are feel free to browse over the [dataset](https://www.dropbox.com/sh/ifwczokjptt6re0/AADv1VarJoQ6IgIitZBzG5c6a?dl=0) for the paper.] and also the anonymous companies's revenue and P&L to analyse the portion of smart punters among the customers in [Analyse the Finance and Stocks Price of Bookmakers](https://github.com/scibrokes/analyse-the-finance-and-stocks-price-of-bookmakers). However the betslip of every single bet require to analyse it. The sparkR amd RHadoop as well as noSQL require in order to analyse the multiple millions bets. It is interesting to analyse *the threaten of hedge fund*^[Kindly refer to [富传奇色彩的博彩狙击公司EM2](https://englianhu.wordpress.com/sportsbook/%E5%AF%8C%E4%BC%A0%E5%A5%87%E8%89%B2%E5%BD%A9%E7%9A%84%E5%8D%9A%E5%BD%A9%E7%8B%99%E5%87%BB%E5%85%AC%E5%8F%B8em2-expectation-maximization/) to know the history and the threaten of EM2 sportsbook consultancy company to World wide known bankers.] since there has a anonymous brand among the brands under Caspo Inc had closed due to a lot of smart punters' stakes and made loss. Well, here I leave it for future research^[Here I put in [6.2 Future Works].] if the dataset is available.

## 4.3 Kelly Ⓜodel

### 4.3.1 Basic Kelly Ⓜodel

  From the papers *Niko Marttinen (2001)*^[Kindly refer to 1th paper in [Reference for industry knowdelege and academic research portion for the paper.]] and *Jeffrey Alan Logan Snyder (2013)*^[Kindly refer to 2nd paper in [Reference for industry knowdelege and academic research portion for the paper.] under **7.4 References**] both applying **Full-Kelly**,**Half-Kelly** and also **Quarter-Kelly** models which similar with my previous Kelly-Criterion model *®γσ, Eng Lian Hu 2014*^[Kindly refer to 4th paper in [Reference for industry knowdelege and academic research portion for the paper.] in **7.4 References** which had applied it and generates an impressive return.] but enhanced. *Niko Marttinen (2001)* has concludes that the basic Kelly criterion generates the highest returns in long run compare to fractional Kelly models.

<iframe src="https://raw.githubusercontent.com/scibrokes/betting-strategy-and-model-validation/8adcccbde5140a4321bf064ef2e065551bc195ed/references/Creating%20a%20Profitable%20Betting%20Strategy%20for%20Football%20by%20Using%20Statistical%20Modelling.pdf" style="width:560px; height:500px;" frameborder="0"></iframe>

<br>

<iframe width="560" height="315" src="https://www.youtube.com/embed/kOvJGcxtIp4" frameborder="0" allowfullscreen></iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/-ePZ9WuIrVQ" frameborder="0" allowfullscreen></iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/iykpeZtoNIk" frameborder="0" allowfullscreen></iframe>

  To achieve the level of profitable betting, one must develop a correct money management procedure. The aim for a punter is to maximize the winnings and minimize the losses. If the punter is capable of predicting accurate probabilities for each match, the *Edward O. Thorp (2006)*^[Kindly refer to 6th paper in [Reference for industry knowdelege and academic research portion for the paper.] in **7.4 References**] has proven to work effectively in betting. It was named after an American economist *John Kelly (1956)*^[Kindly refer to 26th paper in [Reference for industry knowdelege and academic research portion for the paper.] in **7.4 References**] and originally designed for information transmission. The Kelly criterion is described below:

![*figure 4.3.1.1 : Kelly criterion formula.*](figure/Kelly.png)

$$S = \frac{\rho_{EM} \times BK_{Decimal\ odds} - 1} {BK_{HK\ odds}} \cdots equation\ 4.3.1.1$$

  - Where $S$ is the stake expressed as a fraction of one's total bankroll.
  - $\rho_{EM}$ is probability of an event to take place and 
  - while $BK_{Decimal\ odds}$ is decimal odds (decimal odds the return rates with capital stakes) and $BK_{HK\ Odds}$ (HK odds is the net profit rates without capital stakes) for an event offered by the bookmaker.

  Due to HK odds or decimal odds start from range $(0,\infty]$ and return will be $[0,\infty]$, therefore logarithmic function required. For Malay odds $[-1,1]$ no need logarithm. Here I switch from *equation 4.3.1.1* to *equation 4.3.1.2* as below.

$$log(S) = log(\rho_{EM}) + log(BK_{Decimal\ odds} - 1) - log(BK_{HK\ odds}) \cdots equation\ 4.3.1.2$$

  Three important properties, mentioned by *Hausch and Ziemba (1994)*^[You can refer to [Efficiency of Racetrack Betting Markets (2008 Preface Edition)](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Efficiency%20of%20the%20Racetrack%20Betting%20Market%20(2008%20Edition).pdf) which is 29th paper in [Reference for industry knowdelege and academic research portion for the paper.] or [*Chapter 18 Efficiency of Sports and Lottery Betting Markets* in **FINANCE**](https://books.google.com.my/books?id=XC4fZPbT1SQC&printsec=frontcover&dq=Handbooks+in+Operations+Research+and+Management+Science+Finance&hl=en&sa=X&ved=0ahUKEwj7lIj5pLLPAhXGVZQKHf_LC-4Q6AEIPjAE#v=onepage&q&f=false) for further study about Hausch and Ziemba's researchs.] arise when using this criterion to determine a proper stake for each bet:

  - It maximizes the asymptotic growth rate of capital
  - Asymptotically, it minimizes the expected time to reach a specified goal
  - It outperforms in the long run any other essentially different strategy almost surely

![*figure 4.3.1.2 : Example of application Kelly criterion.*](figure/Kelly.jpg)

  The criterion is known to economists and financial theorists by names such as the geometric mean maximizing portfolio strategy, the growth-optimal strategy, the capital growth criterion, etc. We will now show that Kelly betting will maximize the expected log utility for sports-book betting.

<s>
```{r data-return-summary-table3, eval = FALSE, echo = FALSE, results = 'asis'}
## Load package again due to cannot find the function
suppressMessages(library('formattable'))

## Get the investment return rates per annun
## http://www.math.ku.dk/~rolf/teaching/thesis/DixonColes.pdf
## value rRates is based on annual EMProb/netProb ratio, while EMProb get from equation 4.1.2
## due to subset doesn't work, here I add the subset function again.
m <- ddply(dat, .(Sess), summarise, Stakes = sum(Stakes), PL = sum(PL), n = length(Sess), rRates = PL / Stakes) %>% mutate(Stakes = currency(Stakes), PL = currency(PL), rRates = percent(rRates)) %>% tbl_df

m %>% formattable(list(

  Stakes = color_tile('white', 'darkgoldenrod'),
  Return = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'green', 'gray')), x ~ sprintf('%.2f (rank: %02d)', x, rank(-x))),
  n = color_tile('white', '#9B870C'),
  rRates = formatter('span', style = x ~ style(color = ifelse(rank(-x) <= 3, 'green', 'gray')), x ~ sprintf('%.4f (rank: %02d)', x, rank(-x)))
)) %>% as.htmlwidget
```

*table 4.3.1.1* : `r paste0(dim(m), collapse = ' x ')` : *Return of annually investment summary table without cancelled bets.*^[the `rRates` is the mean value of annual return rates which is the return divides by stakes but ommit the cancelled/voided bets to avoind the bias.]

  The `rRates` value from table above excludes the `Cancelled` bets. By refer to *equation 4.3.1.2*, now we fit the adge value from *equation 4.1.1* into it to get the `rEMProbB2` and `rEMProbL2` with known staked value $S$^[Although the result will not be accurate due to the we mention at first, the firm A will not only place bets via only agent A. Let say edge of 0.10 and 0.20 also placed maximum bet HKD40000 but the firm A might placed different amount through other agency based on different edge. However based on the stakes we can reverse the optimal EM Odds.] to replace the existing EM value.
</s>^[Initially think of linear modelling and get the mean value, the positive standard deviation value will be counted as edge range and the residuals value will be the different within the stakes across the leagues. It will similar with proportional staking model as states in paper **Good and bad properties of the Kelly criterion** *by MacLean, Thorp and Ziemba (2010)* and concludes that the Full-Kelly model is the best model for long run, you can refer to the reference in [Kelly Criterion - Part II](https://github.com/scibrokes/kelly-criterion) for further understanding.]

$$log(\rho_{EM}) = log(S) + log(BK_{HK\ odds} + 1) - log(BK_{Decimal\ odds}) \cdots equation\ 4.3.1.3$$

  Although the Kelly model is very simple, but we need to seperates the staking based on different leagues or time range to make it applicable to real world. I don't pretend to know the correct model again but guess the applicable model by testing few models and choose the best among them.
  
  We try to apply the *equation 4.3.1.3* to get the Kelly stakes for every single soccer match.

  Due to there have few reference papers conducting few staking strategics and concludes full Kelly model is the best fit and most profitable along the long term investment, here I try to simuulate the half-Kelly and also quadruple-Kelly, as well as double-Kelly staking model etc and get the optimal weighted control parameter.^[There has a reference paper in section 2 of [Application of Kelly Criterion model in Sportsbook Investment](https://github.com/scibrokes/kelly-criterion) has compare few models as well and also provides the pro-and-con of Kelly model in investment. However, Kelly model will be the best across the long term investment.] Besides, there have few papers doing research and also critic on the Kelly model in investment in financial market and also betting market (includes the rebates of the credit market as well), PIMCO's fund manager **Bill Gross** who manage more than one trillion USD funds applied Kelly model for portfolio, **George Soros** and **Warren Buffet** also applied similar theoty or method with Kelly although there has no evidence to proof it. You are feel free to know in later section [4.5 Staking Ⓜodel and Ⓜoney Ⓜanagement]. For further details kindly refer to [Application of Kelly Criterion model in Sportsbook Investment](https://github.com/scibrokes/kelly-criterion).

  Fractional Kelly models are the weight function for Kelly criterion When we talk about weight function in Kelly model. [A Response to Professor Paul A Samuelson's Objections to Kelly Capital Growth Investing](https://github.com/scibrokes/kelly-criterion/blob/master/references/A%20Response%20to%20Professor%20Paul%20A%20Samuelson's%20Objections%20to%20Kelly%20Capital%20Growth%20Investing.pdf) has talk about the investment portfolio and compare the double-Kelly, full-Kelly, half-Kelly, quadruple-Kelly and also proportional betting across different stages of iterations and concludes that the full-Kelly will be the best fit and growth beyond the ages. Well, fractional-Kelly (means double-Kelly, half-Kelly and quadruple-Kelly but not full-Kelly model) models will be elastics and lesser will be more conservative and double-Kelly will be very risky and eventually going to bankcrupt due to the staking leverages ratio is twice of full-Kelly and over the sustainability of capital. and For further details kindly refer to [Application of Kelly Criterion model in Sportsbook Investment](https://github.com/scibrokes/kelly-criterion). Therefore in last basic Kelly we use the full-Kelly within same leagues but due to there has different levels of risk setting across different soccer leagues. Therefore a weight function needed to make the staking strategy flexible, and it is term as Kelly portfolio to diversified the investment.

### 4.3.2 Fractional Kelly Ⓜodel

  Now we try to fit a weight function into basic Kelly model to be fractional Kelly model. I try to use log to test the maximum value of weight parameter. You can just simply use $w = \frac{1}{4}$ or $log(w) = \frac{1}{2}$ while $w$ is a vector. Please be mind that the value greater than 1 will be risky since involve leverage and lesser will be more conservative.

$$log(w_{i}) + log(\rho_{i}) \cdots equation\ 4.3.2.1$$

  From *Niko Marttinen (2001)*, we can know the full-Kelly generates couple times profit compare to fractional Kelly-models. However there has two points need to be enhanced.
  
  - The high risk at the beginning period of investment.
  - Test on different level of edge and concludes that the 145% generates the highest return.

  Below *Fabián Enrique Moya (2012)* also test the fractional Kelly models with diversify money management methods.

<iframe src="https://raw.githubusercontent.com/scibrokes/betting-strategy-and-model-validation/c2da2e5ca09aaf218616045031c9ee4ce3537b18/references/Statistical%20Methodology%20for%20Profitable%20Sports%20Gambling.pdf" style="width:560px; height:500px;" frameborder="0"></iframe>

```{r lprofile, echo = FALSE, results = 'asis'}

#'@ lRiskProf <- dat[c('League', 'Stakes', 'HCap', 'Result', 'PL')] %>% tbl_df %>% .[sort(.$League), ] %>% unique %>% na.omit %>% mutate(Stakes = currency(Stakes), PL = currency(PL))
lRiskProf <- ddply(dat[c('League', 'Stakes')], .(League), summarise, min = currency(min(Stakes)), mean = currency(mean(Stakes)), median = currency(median(Stakes)), sd = currency(sd(Stakes)), max = currency(max(Stakes))) %>% tbl_df %>% .[sort(.$League), ] %>% unique %>% na.omit

tagList(
  tags$div(align = "center", 
           class = "bg-info", 
           tags$h3(class = "bg-primary", "League Stakes Profiling"), 
           tags$h5(align = "center", class = "text-muted", 
                   "Stakes of Firm A at Agency A (2011~2015) ($0,000)")), 
  as.htmlwidget(lRiskProf %>% .[sample(1:nrow(.), 6), ] %>% formattable(list(
    Stakes = color_tile('white', 'darkgoldenrod')
    ))))
```

*table 4.3.2.1* : `r paste0(dim(lRiskProf), collapse = ' x ')` : *League stakes profiling of firm A from 2011~2015.*

  Above league risk profile suppose to stores the maximum bet for every single league but I only randomly select 6 leagues as sample. However due to I've not yet write a function for real time API^[There are a lot of real time XML odds price and staking softwares similar with **4lowin2** which was states at the begining section in Part I] with operators and test the maximum stakes per bet therefore here I reverse the both mean and median value as the baseline stakes for every single league with a certain range of standard deviation for monte carlo simulation in later section.

```{r data-Kelly, eval = FASLE, echo = FALSE, results = 'asis'}
suppressMessages(library('knitr'))

## Kelly Criterion model
##
## Advantages = (prob of win * decimal odds) + (prob of lose * -1)
## Optimal Kelly wager % = Advantages / decimal odds
## From below data we can know the difference between the Kelly reversed rEMProbB
##

##
## Kelly model
##
## KStakes = exp((log(1000) * HKPrice + 1) / EUPrice) #testing... need to group by leagues due to difference of risk setting.
dat %<>% mutate(
  PropHKPriceEdge = ((Stakes / 10000 * netEMEdge) * HKPrice + 1) / EUPrice,
  
  PropnetProbBEdge = ((Stakes / 10000 * netEMEdge) * (1 / rEMProbB - 1) + 1) / (1 / rEMProbB),
  
  KProbHKPrice = ((Stakes / 10000) * HKPrice + 1) / EUPrice, 
  
  KProbnetProbB = ((Stakes / 10000) * (1 / rEMProbB - 1) + 1) / (1 / rEMProbB),
                
  KProbFixed = exp((log(Stakes / 10000) * HKPrice + 1) / EUPrice), 
  
  KProbFixednetProbB = exp(((log(Stakes / 10000)) * (1 / rEMProbB - 1) + 1) / (1 / rEMProbB)),
  
  KEMProb = (rEMProbB * HKPrice + 1) / EUPrice, 
  
  KEMProbnetProbB = (rEMProbB *  (1 / rEMProbB - 1) + 1) / (1 / rEMProbB),
  
  KProbHalf = ((0.5 * Stakes / 10000) * HKPrice + 1) / EUPrice, 
  
  KProbHalfnetProbB = ((0.5 * Stakes / 10000) * (1 / rEMProbB - 1) + 1) / (1 / rEMProbB), 
  
  KProbQuarter = ((0.25 * Stakes / 10000) * HKPrice + 1) / EUPrice, 
  
  KProbQuarternetProbB = ((0.25 * Stakes / 10000) * (1 / rEMProbB - 1) + 1) / (1 / rEMProbB), 
  
  KProbAdj = exp((log(Stakes / 10000) * HKPrice + 1) / EUPrice), 
  
  KProbAdjnetProbB = exp((log(Stakes / 10000) * (1 / rEMProbB - 1) + 1) / (1 / rEMProbB)), 
  
  KHalfAdj = exp((log(0.5 * Stakes / 10000) * HKPrice + 1) / EUPrice), 
  
  KHalfAdjnetProbB = exp((log(0.5 * Stakes / 10000) * (1 / rEMProbB - 1) + 1) / (1 / rEMProbB)), 
  
  KEMQuarterAdj = exp((log(0.25 * Stakes / 10000) * HKPrice + 1) / EUPrice), 
  
  KEMQuarterAdjnetProbB = exp((log(0.25 * Stakes / 10000) * (1 / rEMProbB - 1) + 1) / (1 / rEMProbB)), 
  
  KStakes = (Stakes * HKPrice + 1) / EUPrice, 
                
  KStakesFixed = exp((log(Stakes) * HKPrice + 1) / EUPrice), 
                
  KStakesEMProb = (as.numeric(rEMProbB * 100) * HKPrice + 1) / EUPrice, 
                
  KStakesHalf = (0.5 * Stakes * HKPrice + 1) / EUPrice, 
                
  KStakesQuarter = (0.25 * Stakes * HKPrice + 1) / EUPrice, 
                
  KStakesAdj = exp((log(Stakes) * HKPrice + 1) / EUPrice), 
                
  KStakesHalfAdj = exp((log(0.5 * Stakes) * HKPrice + 1) / EUPrice), 
                
  KStakesQuarterAdj = exp((log(0.25 * Stakes) * HKPrice + 1) / EUPrice), 
                
  KReturn = ifelse(Result == 'Win', KStakes * EUPrice, ifelse(Result == 'Half Win', KStakes * (HKPrice * 0.5 + 1), ifelse(Result == 'Push'|Result == 'Cancelled', KStakes, ifelse(Result == 'Half Loss', KStakes * 0.5, ifelse(Result == 'Loss', 0, NA))))),  
  
  KReturnFixed = ifelse(Result == 'Win', KStakesFixed * EUPrice, ifelse(Result == 'Half Win', KStakesFixed * (HKPrice * 0.5 + 1), ifelse(Result == 'Push'|Result == 'Cancelled', KStakesFixed, ifelse(Result == 'Half Loss', KStakesFixed * 0.5, ifelse(Result == 'Loss', 0, NA))))), 
                
  KReturnEMProb = ifelse(Result == 'Win', KStakesEMProb * EUPrice, ifelse(Result == 'Half Win', KStakesEMProb * (HKPrice * 0.5 + 1), ifelse(Result == 'Push'|Result == 'Cancelled', KStakesEMProb, ifelse(Result == 'Half Loss', KStakesEMProb * 0.5, ifelse(Result == 'Loss', 0, NA))))),
                
  KReturnHalf = ifelse(Result == 'Win', KStakesHalf * EUPrice, ifelse(Result == 'Half Win', KStakesHalf * (HKPrice * 0.5 + 1), ifelse(Result == 'Push'|Result == 'Cancelled', KStakesHalf, ifelse(Result == 'Half Loss', KStakesHalf * 0.5, ifelse(Result == 'Loss', 0, NA))))),
                
  KReturnQuarter = ifelse(Result == 'Win', KStakesQuarter * EUPrice, ifelse(Result == 'Half Win', KStakesQuarter * (HKPrice * 0.5 + 1), ifelse(Result == 'Push'|Result == 'Cancelled', KStakesQuarter, ifelse(Result == 'Half Loss', KStakesQuarter * 0.5, ifelse(Result == 'Loss', 0, NA))))), 
                
  KReturnAdj = ifelse(Result == 'Win', KStakesAdj * EUPrice, ifelse(Result == 'Half Win', KStakesAdj * (HKPrice * 0.5 + 1), ifelse(Result == 'Push'|Result == 'Cancelled', KStakesAdj, ifelse(Result == 'Half Loss', KStakesAdj * 0.5, ifelse(Result == 'Loss', 0, NA))))), 
                
  KReturnHalfAdj = ifelse(Result == 'Win', KStakesHalfAdj * EUPrice, ifelse(Result == 'Half Win', KStakesHalfAdj * (HKPrice * 0.5 + 1), ifelse(Result == 'Push'|Result == 'Cancelled', KStakesHalfAdj, ifelse(Result == 'Half Loss', KStakesHalfAdj * 0.5, ifelse(Result == 'Loss', 0, NA))))), 
                
  KReturnQuarterAdj = ifelse(Result == 'Win', KStakesQuarterAdj * EUPrice, ifelse(Result == 'Half Win', KStakesQuarterAdj * (HKPrice * 0.5 + 1), ifelse(Result == 'Push'|Result == 'Cancelled', KStakesQuarterAdj, ifelse(Result == 'Half Loss', KStakesQuarterAdj * 0.5, ifelse(Result == 'Loss', 0, NA)))))) %>% tbl_df

## ----------------------
## comparison among the Kelly models and the existing staking model by firm A.
# > dat %>% mutate(KStakes = round((Stakes * HKPrice + 1) / EUPrice, 2), KStakes2 = exp((log(1000) * HKPrice + 1) / EUPrice), KReturn = ifelse(Result == 'Win', KStakes * EUPrice, ifelse(Result == 'Half Win', KStakes * (HKPrice * 0.5 + 1), ifelse(Result == 'Push'|Result == 'Cancelled', KStakes, ifelse(Result == 'Half Loss', KStakes * 0.5, ifelse(Result == 'Loss', 0, NA))))), KReturn2 = ifelse(Result == 'Win', KStakes2 * EUPrice, ifelse(Result == 'Half Win', KStakes2 * (HKPrice * 0.5 + 1), ifelse(Result == 'Push'|Result == 'Cancelled', KStakes2, ifelse(Result == 'Half Loss', KStakes2 * 0.5, ifelse(Result == 'Loss', 0, NA)))))) %>% select(Stakes, KStakes, KStakes2, Return, KReturn, KReturn2) %>% data.frame %>% colSums %>% t %>% tbl_df %>% mutate(Rates = Return / Stakes, KRates = KReturn / KStakes, KRates2 = KReturn2 / KStakes2)
# # A tibble: 1 × 9
#    Stakes  KStakes KStakes2  Return  KReturn KReturn2    Rates   KRates  KRates2
#     <dbl>    <dbl>    <dbl>   <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
# 1 1663757 816210.6  2001767 1699530 833733.8  2066365 1.021501 1.021469 1.032271## ----------------------

## Omit both proportional betting strategics below due to full-Kelly model is proved as the best betting models.
##
## Proportional staking model 1
#'@ pp1 <- dat %>% mutate(PP1Stakes = Stakes * )

## Proportional staking model 2
#'@ pp2 <- dat %>% mutate(PP2AStakes = Stakes / HKPrice, PP2ADiff = PP2AStakes - Stakes, PP2BStakes = Stakes / ) #payout for even price.

Kprof <- dat %>% select(HCap, rEMProbB, KProb, KProbFixed, KEMProb, KProbHalf, KProbQuarter, KProbAdj, KHalfAdj, KEMQuarterAdj, Stakes, KStakes, KStakesFixed, KStakesEMProb, KStakesHalf, KStakesQuarter, KStakesAdj, KStakesHalfAdj, KStakesQuarterAdj, Result, Return, KReturn, KReturnFixed, KReturnEMProb, KReturnHalf, KReturnQuarter, KReturnAdj, KReturnHalfAdj, KReturnQuarterAdj)

kable(summary(Kprof), caption = 'Table 4.3.2.2 : Summary Table of Various Kelly Models')
```

*table 4.3.2.2* : `r paste0(dim(Kprof), collapse = ' x ')` : *League stakes profiling of firm A from 2011~2015.*

```{r}
Edge <- Kprof %>% select(-HCap, -Result) %>% .[c(1:9)] %>% colMeans %>% percent
Edge[c('KProb', 'KEMProb', 'KProbHalf', 'KProbQuarter')] <- Edge[c('KProb', 'KEMProb', 'KProbHalf', 'KProbQuarter')]/(1 - Edge[c('KProb', 'KEMProb', 'KProbHalf', 'KProbQuarter')]) - 1
Edge['rEMProbB'] <- Edge['rEMProbB'] * 100 - 1

KK <- Kprof %>% select(-HCap, -Result) %>% .[-c(1:9)] %>% colSums %>% matrix(nrow = 9, dimnames = list(names(.)[1:9], c('Stakes', 'Return'))) %>% tbl_df %>% mutate(Stakes = currency(Stakes), Return = currency(Return), PL = Return - Stakes, PL.R = percent(PL / Stakes))
sumd <- data.frame(Edge, KK) %>% tbl_df
rm(Edge, KK)

tagList(
  tags$div(align = "center", 
           class = "bg-info", 
           tags$h3(class = "bg-primary", "Profit and Loss of Diversified Investment"), 
           tags$h5(align = "center", class = "text-muted", 
                   "Various Kelly Staking Models and Profit and Loss (2011-2015) ($0,000)")), 
  as.htmlwidget(sumd %>% formattable))
```

*table 4.3.2.3* : `r paste0(dim(sumd), collapse = ' x ')` : *P&L of multiple Kelly models from 2011~2015.*

### 4.3.3 Dynamic Kelly Ⓜodels

  Due to fractional Kelly model is independent models (for example : half-Kelly will be half-Kelly staking model, and full-Kelly will be only full-Kelly model across the years as we made comparison in *table 4.3.3.3*.), now we need to make it dynamic fractional model. Similar with my prevous Rmodel which applied on Poisson model. Due to the calculation of the settlement and result on the win and loss of Asian Handicap is different with Fixed odds, the probabilities of the outcome will be descrete and the measurement of the `likelihood` result required in order to maximize the profit. here we need to add an additional parameter controller to adjust the staking amount on every single match.

  Now I try to will simulate an enhanced Kelly model on staking which take the effect of the outcome of the result into calculation below controller parameter $\phi(r)$ fit into $equation\ 4.3.3.1$ to control the leverage ratio.^[similar theory apply on investment portfolio while it might turn to be nested controller parameters across different soccer leagues.]

$$\phi(r) = exp(w_{i}\rho_{i}) \cdots equation\ 4.3.3.1$$
 Where $X = x_{i,2,3...n}$ is the original staking amount by Kelly model. Meanwhile, the $r$ value is the optimal parameter controller for staking.

$$r\begin{Bmatrix}
=& Win\\
=& Half\ Win\\
=& Push\\
=& Half\ Loss\\
=& Loss\end{Bmatrix} \cdots equation\ 4.3.3.2$$



```{r}
## Random pick 2 observations among each stratified levels of Result.
K <- llply(split(dat, dat$Result), function(x) x[sample(nrow(x), 2), c('Result', 'KReturn', 'Return', 'EUPrice', 'HKPrice', 'KStakes', 'Stakes', 'Rebates')]) %>% ldply(., .id = 'Result') %>% mutate(KReturn = currency(KReturn), Return = currency(Return), KStakes = currency(KStakes), Stakes = currency(Stakes), Rebates = percent(Rebates), Change = percent(KStakes / Stakes - 1)) %>% .[sample(nrow(.), nrow(.)), ]

## http://www.w3schools.com/colors/colors_picker.asp
K %>% formattable(list(
    Result = formatter('span', style = x ~ ifelse(x == 'Win', style(color = '#269900', font.weight = 'bold'), ifelse(x == 'Half Win', style(color = '#40FF00'), ifelse(x == 'Push', style(color = '#FFFF00'), ifelse(x == 'Half Loss', style(color = '#FF8C1A'), ifelse(x == 'Loss', style(color = '#FF0000', font.weight = 'bold'), NA)))))),
    KReturn = formatter('span', style = ~ style(color = ifelse(KReturn >= KStakes, 'green', 'red')), ~ icontext(ifelse(KReturn >= KStakes, 'plus-sign', 'minus-sign'), KReturn)),
    Return = formatter('span', style = ~ style(color = ifelse(Return >= Stakes, 'green', 'red')), ~ icontext(ifelse(Return >= Stakes, 'plus-sign', 'minus-sign'), Return)),
    EUPrice = color_tile('white', '#003D99'),
    HKPrice = color_tile('white', '#003D99'),
    KStakes = color_tile('white', '#CC9900'),
    Stakes = color_tile('white', '#CC9900'),
    
    Change = formatter('span', style = ~ style(color = ifelse(Change < 0, 'red', 'green')), ~ icontext(ifelse(Change < 0, 'arrow-down', 'arrow-up'), Change))))
```

*table 4.3.3.1* : `r paste0(dim(K), collapse = ' x ')` : *Kelly stakes and firm A's stakes of annually investment summary table.*^[The annum return rates but not all data return rates since we need to use the return of that particular year to reverse. The weight parameter in later section will take last year performance to be weight controller. Due to the firm A does not only placed bets with one agent but couples of agencies. Let say placed one millions HKD on a soccer match with higher price simultaniously compare to placed bets on one agency with price decreasingly, therefore the Kelly stakes will definately defferent with firm A's stakes.]

```{r }
suppressMessages(library('tidyverse'))

## weight function to get the likelihood staking amount, maximum likelihood methos will be applicable in section 4.5 and 4.6
#'@ n <- length(levels(dat$Result)) * nrow(dat)
#'@ mtx <- matrix(rep(0, n), nc = length(levels(dat$Result)), dimnames = list(NULL, levels(dat$Result))) %>% as.data.frame %>% tbl_df
#'@ mtx %<>% mutate(`Win` = ifelse(dat$Result == 'Win', 1, 0), `Half Win` = ifelse(dat$Result == 'Half Win', 1, 0), Push = ifelse(dat$Result == 'Half Loss', 1, 0), `Half Loss` = ifelse(dat$Result == 'Half Loss', 1, 0))

mtx <- dat %>% spread(Result, Stakes, fill = 0)
weight <- lm(Return ~ Win + `Half Win` + Push + `Half Loss` + Loss, data = mtx[c('Return', 'KStakes', 'Win', 'Half Win', 'Push', 'Half Loss', 'Loss')])
```

**Bank Roll**

```{r}
suppressMessages(library('htmltools'))

ddply(K, .(Result), summarise, KReturn = sum(KReturn), Return = sum(Return), EUPrice = mean(EUPrice), HKPrice = mean(HKPrice), KStakes = sum(KStakes), Stakes = sum(Stakes), Rebates = sum(Rebates), Change = mean(Change)) %>% mutate(Stakes = currency(Stakes)) %>% tbl_df %>% formattable %>% as.htmlwidget
```

```
## Draft the further modelling
- Summarise the return
- measure the edge of odds price for staking
  + ln(Edge) = ln(Stakes) - ln(HKPrice) , Stakes/HKPrice
  + ln(Stakes) - ln(EUPrice) = (ln(Stakes) - ln(HKPrice)) - ((ln(Stakes) - ln(HKPrice)) + Stakes)
- generalize Kelly model
- Added the weight function
- simulate with different result and score
- Application of Maximum likelihood, Resampling and iteration to get the optimal weight value
- Simulate to compare the result or investment
```


```{r}
## 1. Summarise the data which group by Date
accBets <- ddply(dat, .(Date), summarise, Stakes = sum(Stakes), S.median = median(Stakes), S.mean = mean(Stakes), S.sd = sd(Stakes), Count = length(PL), PL = sum(PL), PL.percent = PL / Stakes)

## 2. Set initial bankroll as 1,000,000
dat$iniBR <- c(1000000, cumsum(dat$Return[-1]))
dat$K <- ((dat$EUPrice + 1) * dat$rEMProbB - 1) / (dat$EUPrice)

exp(mean(log(dat$Stakes)))
```

  There has few points we need to consider, there the we need to retrieve the initial investment capital $BR$:
  
  - risk averse from ruin^[The daily lost cannot over the investment fund, otherwise will be bankrupt before growth, Kelly model is sort of risky at the beginning period but bacame stable as time goes by.]
  - Initial invested capital
  - The differences of time zone (British based sports consultancy firm A)
  - The financial settlement time of Asian operators (daily financial settlement time 12:00PM Hong Kongnese GMT+8 Credit market with rebates)^[Here I follow the kick-off time from GMT+8 1200 until next morning 1159 (or the American Timezone which is GMT - 4) considered as a soccer betting date. Re-categorise the soccer financial settlement date. Due to I have no the history matches dataset from bookmakers. The scrapped spbo time is not stable (always change, moreover there just an information website) where firm A is the firm who placed bets with millions HKD (although the kick-off time might also changed after placed that particular bet), therefore I follow the kick-off time of the firm A.]

```{r bank-roll, echo = FALSE, results = 'asis'}
suppressMessages(library('knitr'))

## Re-categorise the soccer financial settlement date. Due to I have no the history matches dataset from bookmakers. The scrapped spbo time is not stable (always change, moreover there just an information website) where firm A is the firm who placed bets with millions HKD (although the kick-off time might also changed after placed that particular bet), therefore I follow the kick-off time of the firm A.
dat <- dat[order(dat$DateUK),] %>% mutate(DateUS = as.Date(format(DateUK, tz = 'EST', usetz = TRUE, format = '%Y-%m-%d %H:%M:%S'))) #daily settlement will base on variable `DateUS`.

BR <- ddply(dat, .(DateUS), summarise, Stakes = sum(Stakes), Return = sum(Return), PL = sum(PL), n = length(Sess), rRates = Return / Stakes) %>% mutate(CumStakes = cumsum(Stakes), SPL = cumsum(PL), BR = ifelse(4600 + SPL > 0, 4600 + SPL, -9999), gRates = c(1, exp(diff(log(BR), lag = 1))), gRates2 = BR/BR[1]) %>% tbl_df

#'@ write.csv(BR, file = './data/BankRoll.csv')

## Due to our bank roll cannot be less than 0, otherwie will be ruined. Therefore I added the initial balance of the account from the min value of variable `SPL` which is the balance before place bets must be more than 0. Otherwise unable to place bets.
kable(summary(BR), caption = "Table 4.3.2 : Summary data of daily bank roll (HKD$0'000)")
```

*table 4.3.1.2* : `r paste0(dim(BR), collapse = ' x ')` : *Sample data of daily bank roll.*

  Due to our bank roll cannot be less than 0, otherwie will be ruined. Therefore I added the initial balance of the account from the min value of variable `SPL` which is the balance before place bets must be more than 0. Otherwise unable to place bets.
  
  From above table summary, we know that the gap of **daily growth rate** (variable *gRates* is geometric growth rates while *gRates2* is initial fund baseline growth rates) is very big which is from `r min(BR$gRates)` to `r max(BR$gRates)` although the median value is `r median(BR$gRates)`. From initial `paste0('HKD\$', r BR$BR[1] * 10000)` lost to `paste0('HKD\$', r min(BR$BR) * 10000)` while the maximum bankroll hit `paste0('HKD\$', r max(BR$BR) * 10000)` which was `r max(BR$BR)/ BR$BR[1]` and the final bankroll is `r tail(BR$BR)[1]/ BR$BR[1]` times initial invested fund. The ^[As I mentioned at the begining of the research paper, the stakes only reflects the profit and loss of agency A but not firm A. Firm A might have deal with 10~50 or even more agencies and the data from year 2011 is not the initial investment year. You are feel free to download the [BankRoll.csv](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/data/BankRoll.csv). We will discuss the inventory management to reduce the risk.] From [BankRoll.csv](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/data/BankRoll.csv) we observe the end of soccer sesson in May 2011 `dat %>% filter(DateUS >= '2011-05-14' & DateUS <= '2011-05-21')` has a seriourly crash. We can investigate more details about the loss matches from the data (or filter the range of the bets in the data table inside [Part I](http://rpubs.com/englianhu/208637)).

```{r br-summary01, eval = FALSE, echo = FALSE, results = 'asis'}
## eval = FALSE to save the file size heavily loading, will summarise after Kelly model and doing comparison at the conclusion section.
## Will need to split the annual and monthly return and set a new initial fund for every month. The profit can 
## 
## monthly summary data table
ddply(BR, .(month(DateUS)), summarise, Stakes = sum(Stakes), Return = sum(Return), PL = sum(PL), n = sum(n), rRates = Return / Stakes, CumStakes = cumsum(Stakes), SPL = cumsum(PL), BR = sum(BR)) %>% mutate(gRates = c(1, exp(diff(log(BR), lag = 1))), gRates2 = BR/BR[1]) %>% tbl_df
#    month(DateUS)    Stakes    Return        PL    n    rRates CumStakes       SPL      BR    gRates   gRates2
# 1              1 132529.90 137572.65  5042.751 2723 1.0380499 132529.90  5042.751 2870710 1.0000000 1.0000000
# 2              2 178758.00 184542.81  5784.814 3741 1.0323611 178758.00  5784.814 2803937 0.9767398 0.9767398
# 3              3 197311.00 200753.10  3442.100 4624 1.0174450 197311.00  3442.100 3333502 1.1888650 1.1612118
# 4              4 190797.00 192263.64  1466.644 4737 1.0076869 190797.00  1466.644 3324891 0.9974167 1.1582120
# 5              5 151884.60 153810.24  1925.639 4288 1.0126783 151884.60  1925.639 3464326 1.0419369 1.2067838
# 6              6  76511.00  70926.86 -5584.136 1679 0.9270153  76511.00 -5584.136 2921503 0.8433105 1.0176934
# 7              7  57176.34  53989.17 -3187.167 1991 0.9442572  57176.34 -3187.167 2699121 0.9238810 0.9402277
# 8              8 147524.50 152946.75  5422.250 4183 1.0367549 147524.50  5422.250 2115689 0.7838436 0.7369914
# 9              9 170805.95 176020.25  5214.300 4205 1.0305276 170805.95  5214.300 2240139 1.0588225 0.7803431
# 10            10 115338.94 118597.68  3258.739 2907 1.0282536 115338.94  3258.739 2053623 0.9167391 0.7153710
# 11            11 115978.00 124308.67  8330.670 3105 1.0718297 115978.00  8330.670 2015532 0.9814519 0.7021022
# 12            12 129142.00 133797.72  4655.721 2872 1.0360512 129142.00  4655.721 2397673 1.1895982 0.8352195

## annual summary data table
ddply(BR, .(year(DateUS)), summarise, Stakes = sum(Stakes), Return = sum(Return), PL = sum(PL), n = sum(n), rRates = Return / Stakes, CumStakes = cumsum(Stakes), SPL = cumsum(PL), BR = sum(BR)) %>% mutate(gRates = c(1, exp(diff(log(BR), lag = 1))), gRates2 = BR/BR[1]) %>% tbl_df %>% formattable %>% as.htmlwidget
#   year(DateUS)   Stakes   Return        PL     n   rRates CumStakes       SPL       BR    gRates  gRates2
# 1         2011 305958.2 312683.6  6725.327  5554 1.021981  305958.2  6725.327  1286022 1.0000000 1.000000
# 2         2012 309850.0 319747.3  9897.320  7392 1.031942  309850.0  9897.320  4931039 3.8343361 3.834336
# 3         2013 436285.5 439093.9  2808.445 10957 1.006437  436285.5  2808.445  8069533 1.6364773 6.274804
# 4         2014 391430.5 406585.2 15154.719 11041 1.038716  391430.5 15154.719 10394713 1.2881430 8.082845
# 5         2015 220233.0 221419.5  1186.515  6111 1.005388  220233.0  1186.515  7559340 0.7272293 5.878081
```


## 4.4 Poisson Ⓜodel

> Data has been collected over the last four seasons in the English Premier League.
These include 1997-1998, 1998-1999, 1999-2000 and 2000-2001 seasons. We
have also collected the season 2000-2001 data from the main European football
betting leagues, such as English Division 1, Division 2 Division 3, Italian Serie A,
German Bundesliga and Spanish Primera Liga...

*quote 4.4.1 : the dataset for the studies (source : Niko Marttinen (2001)).*

  *Niko Marttinen (2001)*^[Kindly refer to 1th paper in [Reference for industry knowdelege and academic research portion for the paper.]] has enhanced the *Dixon and Coles (1996)* which are :
  
  - Basic Poisson model : Independence Poisson model for both home and way teams with a constant home advantage parameter.
  - Independent home advantages model : Seperate the home advantage parameter depends on the teams accordingly.
  - Split season model : Split a soccer league season to be 1st half and 2nd half season.
  - (E) Scores plus Poisson model.

  From above models, the author has compare the efficiency and the best fit model for scores prediction as below.

![*figure 4.4.1 : Comparison of various Poison models (source : Niko Marttinen (2001)).*](figure/NikoMarttinen2001-01.jpg)

  From *figure 4.4.1* above, the author compare the deviance of the models^[Kindly refer to [Generalized Linear Models in R, Part 2: Understanding Model Fit in Logistic Regression Output](http://www.theanalysisfactor.com/r-glm-model-fit/), [devianceTest](http://www.mathworks.com/help/stats/generalizedlinearmodel.deviancetest.html?s_tid=gn_loc_drop) and [Use of Deviance Statistics for Comparing Models](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Use%20of%20Deviance%20Statistics%20for%20Comparing%20Models.pdf) to learn about the method of comparison.]

![*figure 4.4.2 : Comparison of various mixed Poison models II (source : Niko Marttinen (2001)).*](figure/NikoMarttinen2001-02.jpg)

![*figure 4.4.3 : Comparison of various mixed Poison models III (source : Niko Marttinen (2001)).*](figure/NikoMarttinen2001-03.jpg)

  From above models, the author list the models and states even pick the worse model among the models even highly accurate than bookmaker while *E(Score)&Dep&Weighted* is the best.

![*figure 4.4.4 : Comparison of various odds modelling models (source : Niko Marttinen (2001)).*](figure/NikoMarttinen2001-04.jpg)

  Besides, *Niko Marttinen (2001)* not only choose Poison model throughly as the odds modelling model but also compare to below models :-
  
  - ELO ratings.
  - multinomial ordered probit model.
  
  He concludes that the multinomial ordered probit model is the best fit model but the software for fitting is not generally available. Meanwhile, the Poisson model is more versatile than probit logit model based on the dataset accross the European soccer leagues.^[There has a lot of papers with regard to application of logit probit models on soccer betting, might read through and made comparison with my **®Model** *®γσ, Eng Lian Hu (2016)*. I used to read though the logit probit and there has a complicated parameters setting for various effects like : wheather, players' condition, couch, pitch condition and even though the distance travel and the players' stamina modelling.]

  Here we introduce the *Dixon and Coles (1996)* model and its codes. You are freely learning from below links if interest.

  - [Dixon and Cole's Poisson regression R Packages](http://lastplanetranking.blogspot.com/2013/11/code.html)
  - [Dixon and Coles Poisson model](http://opisthokonta.net/?p=890)
  - [Dixon Coles model - Python](http://www.sportshacker.net/posts/simple_dixon_coles.html)
  - [Predicting Football Using R](http://pena.lt/y/2014/11/02/predicting-football-using-r/)

```{r data-Poisson, echo = FALSE, results = 'asis'}
## Load package again due to cannot find the function
suppressMessages(library('DT'))

## Apply Poisson model to simulate different scores to maximum likelihood value ρ.
## reverse Kelly Criterion to abtain the average EMPrice, reversed bivarite poisson to get the EMprobB
##
## benchmarking logistic regression using glm.fit , bigglm, speedglm, glmnet, LiblineaR
## http://stackoverflow.com/questions/19532651/benchmarking-logistic-regression-using-glm-fit-bigglm-speedglm-glmnet-libli
##
## Test if placed multiple bets on same match, merge data files in Part I has checked the multiple-bets in same match. Here we need to filter the unique data for scores modelling.
#'@ preData[duplicated(preData[c('Date', 'Home', 'Away')]), c('Date', 'Home', 'Away', 'HG', 'AG', 'InPlay', 'InPlay2', 'Mins', 'Mins2', 'Picked2')] %>% tbl_df %>% datatable
```

*table 4.4.1 : Samples of filtered multiple bets placed on same matches.*

  Due to the soccer matches randomly getting from different leagues, and also not Bernoulli win-lose result but half win-lose etc as we see from above. Besides, there were mixed Pre-Games and also In-Play soccer matches and I filter-up the sample data to be `r paste(dim(preData), collapse = ' x ')`. I don't pretend to know the correct answer or the model from firm A. However I take a sample presentation *Robert Johnson (2011)*^[Kindly refer to 23th paper in [7.4 References]] from one of consultancy firm which is Dixon-Coles model and omitted the scoring process section.

  Below is my previous research paper which was more sophiscated than Dixon-Coles model. You can refer it and I will just omit the section as mentioned at the beginning section of this staking validation research paper.
  
<iframe src="https://raw.githubusercontent.com/scibrokes/odds-modelling-and-testing-inefficiency-of-sports-bookmakers/master/Odds%20Modelling%20and%20Testing%20Inefficiency%20of%20Sports-Bookmakers/Odds_Modelling_and_Testing_Inefficiency_of_Sports-Bookmakers.pdf" style="width:560px; height:500px;" frameborder="0"></iframe>

  Here I cannot reverse computing from barely $\rho_i^{EM}$ without know the $\lambda_{ij}$ and $\gamma$ values. Therefore I try to using both Home and Away Scores to simulate and test to get the maximum likelihood $\rho_i^{EM}$.

$$X_{ij} = pois(\gamma \alpha_{ij} \beta_{ij} ); Y_{ij} = pois(\alpha_{ij} \beta_{ij}) \cdots equation\ 4.4.1$$
```{r }
## model bivariate poison to retrieve the scores and resampling to get the likelihood value.
#'@ bvp()
```

  In order to minimzie the risk, I tried to validate the odds price range invested by firm A.^[As I used to work in **AS3388** which always take bets from **Starlizard** where they only placed bets within the odds price range from 0.70 ~ -0.70. They are not placed bets on all odds price in same edge]. The sportbook consulatancy firms will not place same amount of stakes on same edge, lets take example as below :-
  
  - $Odds_{em}$ = 0.40 while $Odds_{BK}$ = 0.50, The edge to firm will be 0.5 ÷ 0.4 = `r 0.5/0.4`
  - $Odds_{em}$ = 0.64 while $Odds_{BK}$ = 0.80, The edge to firm will be 0.8 ÷ 0.64 = `r 0.8/0.64`
  
  We know above edge is same but due to the probability of occurance an event/goal at 0.4 is smaller than 0.64. Here I try to bootstrap/resampling the scores of matches of the dataset and apply maximum likelihood on the poisson model to test the Kelly model and get the mean/likelihood value. Boostrapping the scores and staking model will be falling in the following sections [4.5 Staking Ⓜodel and Ⓜoney Management] and  [4.6 Expectation Ⓜaximization and Staking Simulation].

## 4.5 Staking Ⓜodel and Ⓜoney Ⓜanagement

```{r, echo = FALSE, results = 'asis'}
## Bootstrap and apply maximum likelihood model
## Full-Kelly, Half-Kelly, Quarter-Kelly

```

  From the article [凯利模式资金管理](http://ch-hsieh.blogspot.com/2015/01/kelly-criterion-0.html)^[You might refer to [Application of Kelly Criterion model in Sportsbook Investment](https://github.com/scibrokes/kelly-criterion) as well.] we know the application of generalization of Kelly criterion for uneven payoff games.

$$G: = \mathop {\lim }\limits_{N \to \infty } \frac{1}{N}\log\left( {\frac{{{S_N}}}{{{S_0}}}} \right) \cdots equation\ 4.3.2$$

  In order to get the optimal value, I apply the bootrapping and resampling method.
  
$$L(\rho) = \prod_{i=1}^{n} (x_{i}|\rho) \cdots equation\ 4.3.4$$
  
  Now we look at abpve function from a different perspective by considering the observed values $x_{1}, x_{2}, x_{3}… x_{n}$ to be fixed *parameters* of this function, whereas $\rho$ will be the function's variable and allowed to vary freely; this function will be called the [**likelihood**](https://onlinecourses.science.psu.edu/stat414/node/191).

  Below top-up and refill the fund into the pool is another method for risk management on money management while there is very dangerous if that leverage is higher. Similar with high leverage with contra in option market, endless pupm-in the fund will be very dangerous. Therefore we need to simulate what if the initial fund is smaller than the .

![*equation 4.3.3 : Economic Order Quantity (EOQ)*](./figure/EOQ.jpg)

  Base on above euqation, there has some criteria as below :

  - $C$ is the total cycle-inventory cost per annum which is the invest or pump in figure into the investment pool.
  - $Q$ is the fund size which pump into the investment pool. (For example: normally the investment fund or insurance company will advise the investors regularly credit a certain money into whose investment account.) 
  - $H = 1$ due to there has no holding cost per annum unless there is inactive account which will be charges a certain amount of the administration fee where it is not apply to active players.
  - $D$ is the betting stakes per annum.
  - $S = 1$ due to there has no setup costs per lot. (unless we count in the bank charges, for example : western union, Entropay, bank transfer fee, etc)

  You are feel free to know about inventory management via [Module 3: Inventory and Supply Chain Management](http://rpubs.com/englianhu/188394).

```
C = Q/2 + 305958.2/Q
  = Q^2 / 2Q + 611916.4 / 2Q
2QC  = Q^2 + 611916.4
  = Q^2 - 2QC + 611916.4 = 0

Q(Q - 2C) = 611916.4
```

```
Section : reverse modelling to get the EMProb prior to calculate the coefficient of the staking model. Otherwise might rearrange the order of applied Poison model here by refer to international competitions.
```

  *Galema, Plantinga and Scholtens (2008)*^[You are feel free to refer to [Reference for industry knowdelege and academic research portion for the paper.] in **7.4 References** for further details]

### reminder (temporary noted for further):
```
draft : 
  - http://www.moneychimp.com/articles/risk/regression.htm
  - read *Galema, Plantinga and Scholtens (2008)* https://englianhu.files.wordpress.com/2016/06/the-stocks-at-stake-return-and-risk-in-socially-responsible-investment.pdf
  - reverse engineering on staking-profit linear regression model to get/retrieve EMProb value since now only get the coefficients figire of EMProb. Although incompleted soccer teams... 2ndly, reversed poison model from EMProb might is not workable on one-sided competition, need to refer to some international competition as references for incompleted dataset.
```

  *Martin Spann and Bernd Skiera (2009)*^[Kindly refer to 19th paper in [Reference for industry knowdelege and academic research portion for the paper.] under **7.4 References**] applied a basic probability sets on the draw games and also the portion of win and loss. The author simply measured the portion of the draw result with win/loss to get the edge to place a bet. However it made a loss on Italian operator Oddset due to the 25% high vigorish but profitable in 12%. Secondly, the bets placed on fixed odds but not Asian Handicap and also a fixed amount $100.

  sample... Geometric Mean

<iframe width="560" height="315" src="https://www.youtube.com/embed/IH7On9hJsAk" frameborder="0" allowfullscreen></iframe>

[**Parimutuel Betting**](https://en.wikipedia.org/wiki/Parimutuel_betting)

<iframe src="https://raw.githubusercontent.com/scibrokes/kelly-criterion/d12b9b565b49f4b987470ca2cd853619f050594d/references/Kelly%20vs%20Markowitz%20Portfolio%20Optimization.pdf" style="width:560px; height:500px;" frameborder="0"></iframe>

**Investment Portfolio**

*张丹 (2016)*^[Kindly refer to 7th paper inside [Reference for technical research on programming and coding portion for the paper.] in **7.4 References** for further details] provides couple of r package for investment and analysis in financial market.


## 4.6 Expectation Ⓜaximization and Staking Simulation

```{r, echo = FALSE, results = 'asis'}
## Apply Poison model to simulate the result of the matches
## Apply the Kelly model (iterations) to test the efficiency of the value betting from  Sportsbook consultancy firm A
## Apply poisson model to simulate different scores and result to test the efficiency of the staking model.
## reverse Kelly Criterion to abtain the average EMPrice, reversed bivarite poisson to get the EMprobB

```

  Application of Monte Carlo simulation.
  
```
- simulate the resampling the stakes by mean and median value 100 times.
- simulate the poisson models for soccer matches result 100 times.
- simulate the dynamic fractional Kelly model with weight parameter, yearly base.
- simulate whole process until get the optimal value...
```

# 5. ®esult

  - Section [5.1 Comparison of the ®esults] - Comparison of the Returns of Staking Models.
  - Section [5.2 Ⓜarket Basket] - Analyse the Hedging or Double up Invest by Firm A.

## 5.1 Comparison of the ®esults

Chapter 4.2 Comparison of Different Feature Sets and Betting Strategies in []()

```{r, echo = FALSE, results = 'asis'}
## Bootstrap and apply maximum likelihood model 
## http://www.r-bloggers.com/apple-compared-to-others-with-ggthemes/
#'@ 
#'@ kable(dat) ##knit table
```

  *Dixon and Pope (2003)* apply linear model to compare the efficiency of the odds prices offer by first three largest Firm A, B and C in UK.

## 5.2 Market Basket

  By refer to *®γσ, Eng Lian Hu (2016)*^[Kindly refer to 28th paper in [Reference for industry knowdelege and academic research portion for the paper.] under **7.4 References**], here I apply the `arules` and `arulesViz` packages to analyse the market basket of the bets.

```{r gvis-options, echo = FALSE, results = 'asis'}
## Set options back to original options
options(op)
```

# 6. Conclusion

  - Section [6.1 Conclusion] - Conclusion of this Research Paper.
  - Section [6.2 Future Works] - Future Research or Enhancement.

## 6.1 Conclusion

  Due to the data-sets I collected just one among all agents among couple sports-bookmakers [4lowin](https://www.youtube.com/watch?v=eFYS0jdSiWc). Here I cannot determine if the sample data among the population...

> JA : What skills and academic training (example: college courses) are valuable to sports statisticians?

> KW : I would say there are three sets of skills you need to be a successful sports statistician:

>  - Quantitative skills - the statistical and mathematical techniques you'll use to make sense of the data. Most kinds of coursework you'd find in an applied statistics program will be helpful. Regression methods, hypothesis testing, confidence intervals, inference, probability, ANOVA, multivariate analysis, linear and logistic models, clustering, time series, and data mining/machine learning would all be applicable. I'd include in this category designing charts, graphs, and other data visualizations to help present and communicate results.

>  - Technical skills - learning one or more statistical software systems such as R/S-PLUS, SAS, SPSS, Stata, Matlab, etc. will give you the tools to apply quantitative skills in practice. Beyond that, the more self-reliant you are at extracting and manipulating your data directly, the more quickly you can explore your data and test ideas. So being adept with the technology you're likely to encounter will help tremendously. Most of the information you'd be dealing with in sports statistics would be in a database, so learning SQL or another query language is important. In addition, mastering advanced spreadsheet skills such as pivot tables, macros, scripting, and chart customization would be useful.

>  - Domain knowledge - truly understanding the sport you want to analyze professionally is critical to being successful. Knowing the rules of the game; studying how front offices operate; finding out how players are recruited, developed, and evaluated; and even just learning the jargon used within the industry will help you integrate into the organization. You'll come to understand what problems are important to the GM and other decisionmakers, as well as what information is available, how it's collected, what it means, and what its limitations are. Also, I recommend keeping up with the discussions in your sport's analytic community so you know about the latest developments and what's considered the state of the art in the public sphere. One of the great things about being a sports statistician is getting to follow your favorite websites and blogs as a legitimate part of your job!

**source : [Preparing for a Career as a Sports Statistician: Two Interviews with People in the Field](http://stattrak.amstat.org/2012/08/01/sports-statistician/)**

  In this Part II research paper I try to add a section which is filtered out only English soccer leagues and the revenue and profit & loss all sessional based but not annum based to make it applicable to my future staking in real world. The proportional staking and also money management on the staking pools. You are feel free to browse from the content page [Betting Strategy and Model Validation](https://github.com/scibrokes/betting-strategy-and-model-validation).

...
...
...

## 6.2 Future Works

  *Niko Marttinen (2001)* has conducted a very detail and useful but also applicable betting system in real life. There has a ordered probit model which shows a high accuracy predictive model compare to his Poisson (Escore) model. Well, the *®γσ, Lian Hu ENG (2016)*^[The research modelling with testing the efficiency of odds price which had completed in year 2010. Kindly refer to 3rd paper in [Reference for industry knowdelege and academic research portion for the paper.] under **7.4 References**] has build a weight inflated diagonal poisson model which is more complicated and shophitiscated and later *®γσ, Lian Hu ENG (2014)*^[Kindly refer to 4th paper inside [Reference for industry knowdelege and academic research portion for the paper.] under **7.4 References**]. However there has an automatically and systematically trading system which wrote in *VBA + S-Plus + Excel + SQL*^[the betting system has stated in his paper.] which is very useful as reference. The author use VBA to automac the algorithmic trading while there has no Asian Handicap and Goal Line odds price data to simulate compare to mine. While currently the shinyapps with RStudioConnect can also build an algorithmic trading system. However the *session timeout issue*^[The connection timeout issue might be a big issue for real time algorithmic trading] might need to consider. The [shinydashboard example](https://rstudio.github.io/shinydashboard/examples.html) from ｮStudio might probably cope with the issue.
  
  *John Fingleton & Patrick Waldron (1999)* applied Shin model to test the portion of hedge funds and smart punters. As I stated in [4.2 Linear Ⓜodel], the sparkR, RHadoop and noSQL require in order to analyse the high volume betslips dataset. Its interesting and will conduct the research if all betslips of bookmaker(s) is(are) available in the future.

  From the [4.3 Kelly Ⓜodel] we test the staking model, the *table 4.2.1* we apply the linear models and choose the best fit model based on the edge of odds price. [4.4 Poisson Ⓜodel] we try to reverse the odds price placed to get the probabilities of scoring different scores. Now we try to test the return of staking on different handicap (ex: 0, 0.25, 0.5, 0.75, 1 etc.) to know which handicap earn the most. Nowadays the hotest matches of four major leagues provides few handicaps market, there will be another case study and research to increase the profit base on same probabilities  and also edge but staking on different handicap. The dataset will be collect for research beyond the future.

  I will be apply Shiny to write a dynamic website to utilise the function as web based apps. I am currently conducting another research on [Analyse the Finance and Stocks Price of Bookmakers](https://github.com/scibrokes/analyse-the-finance-and-stocks-price-of-bookmakers) which is an analysis on the public listed companies and also anonymous companies revenue and profit & loss. You are welcome to refer [SHOW ME SHINY](http://www.showmeshiny.com/category/topics/sports/) and build your own shinyapps.
  
  I will also write as a package to easier load and log.

  If you get interest to be a punter, you are feel free to read over below presentation paper from a British consultancy firm to know the requirement to be a professional gambler.

<iframe src="https://raw.githubusercontent.com/scibrokes/betting-strategy-and-model-validation/c2da2e5ca09aaf218616045031c9ee4ce3537b18/references/An%20Introduction%20to%20Football%20Modelling%20at%20SmartOdds%20(v1).pdf" style="width:560px; height:500px;" frameborder="0"></iframe>

# 7. Appendices

  - Section [7.1 Documenting File Creation ] - Information of the Paper.
  - Section [7.2 Versions' Log] - Version Log of the Paper.
  - Section [7.3 Speech and Blooper] - Speech and Blooper during Conducting the Research.
  - Section [7.4 References] - Reference Papers for the Paper.

## 7.1 Documenting File Creation 

  It's useful to record some information about how your file was created.

  - File creation date: 2015-07-22
  - File latest updated date: `r Sys.Date()`
  - `r R.version.string`
  - R version (short form): `r getRversion()`
  - [**rmarkdown** package](https://github.com/rstudio/rmarkdown) version: `r packageVersion('rmarkdown')`
  - [**tufte** package](https://github.com/rstudio/tufte) version: `r packageVersion('tufte')`
  - File version: 1.0.0
  - Author Profile: [®γσ, Eng Lian Hu](https://beta.rstudioconnect.com/englianhu/ryo-eng/)
  - GitHub: [Source Code](https://github.com/Scibrokes/Betting-Strategy-and-Model-Validation)
  - Additional session information
  
```{r info, echo = FALSE, warning = FALSE, results = 'asis'}
suppressMessages(require('dplyr', quietly = TRUE))
suppressMessages(require('formattable', quietly = TRUE))

lubridate::now()
sys1 <- devtools::session_info()$platform %>% unlist %>% data.frame(Category = names(.), session_info = .)
rownames(sys1) <- NULL
sys1 %>% formattable %>% as.htmlwidget

data.frame(Sys.info = Sys.info()) %>% formattable %>% as.htmlwidget

rm(sys1)
```

## 7.2 Versions' Log
  
  - File pre-release version: 0.9.0
    + file created
    + Applied **ggplot2**, **ggthemes**, **directlabels** packages for ploting. For example, the graphs applied in Section [2. Data].
  - File pre-release version: 0.9.1
    + Added [Natural Language Analysis](http://rpubs.com/englianhu/natural-language-analysis) which is research for teams' name filtering purpose.
    + Changed from **knitr::kable** to use datatble from **DT::datatable** to make the tables be dynamic.
    + Changed from **ggplot2** relevant packages to **googleVis** package to make graph dynamic.
    + Completed chapter [3. Summarise the Staking Model].
  - File pre-release version: 0.9.2 - *"2016-02-20 09:41:49 JST"*
    + Added Section [7.2 Versions' Log] and Section [7.3 Speech and Blooper] since retest the coding
    + Added Section [4. Staking Model] .
  - File pre-release version: 0.9.3 - *"2016-02-05 05:24:35 EST"*
    + Modified DT::datatable to make the documents can be save as xls/csv
    + Added log file for version upgraded
  - File pre-release version: 0.9.3.1 - *2016-06-22 13:36:33 JST*
    + Reviewed previous version, DT::datatable updated new version replaced *Button* extension from *TableTools*, removed sparkline and htmlwidget
    + Applied linear regression to test the efficiency of staking model by consultancy firm A
  - File pre-release version 0.9.4 - *2016-09-28 00:15:24 JST*
    + Add linear regression and shinyApp to test the effects on staking
    + 

## 7.3 Speech and Blooper

  Firstly I do appreciate those who shade me a light on my research. Meanwhile I do happy and learn from the research.

  Due to the rmarkdown file has quite some sections and titles, you might expand or collapse the codes by refer to [Code Folding and Sections](https://support.rstudio.com/hc/en-us/articles/200484568) for easier reading.

  There are quite some errors when I **knit HTML**:
  
  - let say always stuck (which is not response and consider as completed) at 29%. I tried couple times while sometimes prompt me different errors (upgrade Droplet to larger RAM memory space doesn't helps) and eventually apply `rm() and gc()` to remove the object after use and also clear the memory space.

  - Need to reload the package `suppressAll(library('networkD3'))` which in chunk `decission-tree-A` prior to apply function `simpleNetwork` while I load it in chunk `libs` at the beginning of the section 1. Otherwise cannot found that particlar function.

  - The `rCharts::rPlot()` works fine if run in chunk, but error when knit the rmarkdown file. Raised an issue : [Error : rCharts::rPlot() in rmarkdown file](http://stackoverflow.com/questions/38941927/error-rchartsrplot-in-rmarkdown-file).

  - `xtable` always shows LaTeX output but not table. Raised a question in COS : [求助！knitr Rmd pdf 中文编译 *2016年8月19日 下午9:56 7 楼*](http://cos.name/cn/topic/411119/#post-417637).Here I try other packages like [`textreg`](http://www2.uaem.mx/r-mirror/web/packages/texreg/vignettes/texreg.pdf) and [`stargazer`](http://www.princeton.edu/~otorres/NiceOutputR.pdf). You can refer to [Test version](http://englianhu.github.io/2016/08/Betting%20Strategy%20and%20Model%20Validation/Betting_Strategy_and_Model_Validation_-_Part_02test.html#linear-odel) to view the output of `stargazer` function and the source codes I reserved but added `eval = FALSE` in chunks named `lm-summary` and `lm-anova` to unexecute the codes.
  
  - I refer to [R Shiny: Rendering summary.ivreg output](http://stackoverflow.com/questions/27245173/r-shiny-rendering-summary-ivreg-output) and tried to plot the output table, but there has no bottom statistical information like *Residual standard error*, *Degree of Freedom*, *R-Squared*, *F-statistical value* and also *p-value*, therefore I use [R Shiny App for Linear Regression, Issue with Render Functions](http://stackoverflow.com/questions/33874298/r-shiny-app-for-linear-regression-issue-with-render-functions) which simply `renderPrint()` the `verbatimTextOutput()` in *shinyapp 4.2.1*.
  
  - I tried to raise an issue about post the shinyapps to RStudioConnect at [Unable publish to RStudio Connect : Error in yaml::yaml.load(enc2utf8(string), ...) : Reader error: control characters are not allowed: #81 at 276 #115](https://github.com/rstudio/rsconnect/issues/115). You might try to refer to the gif files in [#issue 115](https://github.com/rstudio/rsconnect/issues/115#issuecomment-244084859) for further information. I tried couple times and find the solution but there has no an effective solution and only allowed post to ｮPubs.com where I finally decide to seperate the dynamic shinyApp into another web url.
  
  - **Remark** : When I rewrite *Report with ShinyApps : Linear Regression Analysis on Odds Price of Stakes* and would like to post to ®StudioConnect, the wizard only allowed me post to rPubs.com (but everyone know rPubs only allow static document which is not effort to support Shinyapp). Therefore kindly refer to <https://beta.rstudioconnect.com/content/1766/>. You might download and run locally due to web base version always affected by wizards and sometimes only view datatable but sometimes only can view googleVis while sometimes unable access.
  
  - [Using formattable and plotly simultaneously](http://stackoverflow.com/questions/39319427/using-formattable-and-plotly-simultaneously) and [Possible namespace issue with plotly::last_plot() #41](https://github.com/renkun-ken/formattable/issues/41#issuecomment-171590677) solved the formattable issue.

  - The analysis in Part I might slightly different with Part II due to the timezone issue.
  
    + The daily financial settlement time is EST 0000 or HKT 1200.
    + The filtered data for observation in Part II for statistical analysis purpose while Part I is just summarise and breakdown the bets which includes all bets.

  - I am currently work as a customer service operator and self research as a smart punter. Hope my sportsbook hedge fund company website **Scibrokes®** running business soon...

![**Terminator II**](figure/Ill-Be-Back-Terminator.gif)

## 7.4 References

####  Reference for industry knowdelege and academic research portion for the paper.

  1. [**Creating a Profitable Betting Strategy for Football by Using Statistical Modelling** *by Niko Marttinen (2006)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Creating%20a%20Profitable%20Betting%20Strategy%20for%20Football%20by%20Using%20Statistical%20Modelling.pdf)
  2. [**What Actually Wins Soccer Matches: Prediction of the 2011-2012 Premier League for Fun and Profit** *by Jeffrey Alan Logan Snyder (2013)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/What%20Actually%20Wins%20Soccer%20Matches%20-%20Prediction%20of%20the%202011-2012%20Premier%20League%20for%20Fun%20and%20Profit.pdf)
  3. [**Odds Modelling and Testing Inefficiency of Sports Bookmakers : Rmodel** by ®γσ, Eng Lian Hu (2016)](https://github.com/scibrokes/odds-modelling-and-testing-inefficiency-of-sports-bookmakers/blob/master/Odds%20Modelling%20and%20Testing%20Inefficiency%20of%20Sports-Bookmakers.pdf)
  4. [**Apply Kelly-Criterion on English Soccer 2011/12 to 2012/13** *by ®γσ, Eng Lian Hu (2014)*](https://github.com/scibrokes/kelly-criterion)
  5. [**The Betting Machine** *by Martin Belgau Ellefsrød (2013)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/The%20Betting%20Machine.pdf)
  6. [**The Kelly Criterion in Blackjack Sports Betting, and the Stock Market** *by Edward Thorp (2016)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/The%20Kelly%20Criterion%20in%20Blackjack%20Sports%20Betting%2C%20and%20the%20Stock%20Market.pdf)
  7. [**Statistical Methodology for Profitable Sports Gambling** *by Fabián Enrique Moya (2012)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Statistical%20Methodology%20for%20Profitable%20Sports%20Gambling.pdf)
  8. [**How to apply the Kelly criterion when expected return may be negative?** *by user1443 (2011)*](http://quant.stackexchange.com/questions/2500/how-to-apply-the-kelly-criterion-when-expected-return-may-be-negative)
  9. [**Money Management Using The Kelly Criterion** *by Justin Kuepper*](http://www.investopedia.com/articles/trading/04/091504.asp)
  10. [**Optimal Exchange Betting Strategy For WIN-DRAW-LOSS Markets** *by Darren O'Shaughnessy (2012)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Optimal%20Exchange%20Betting%20Strategy%20For%20WIN-DRAW-LOSS%20Markets.pdf)
  11. [**Kelly criterion with more than two outcomes** *by David Speyer (2014)*](http://math.stackexchange.com/questions/662104/kelly-criterion-with-more-than-two-outcomes)
  12. [**凯利模式资金管理** *by Chung-Han Hsieh (2015)*](http://ch-hsieh.blogspot.com/2015/01/kelly-criterion-0.html)
  13. [**Optimal Determination of Bookmakers' Betting Odds: Theory and Tests** *by John Fingleton & Patrick Waldron (1999)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Optimal%20Determination%20of%20Bookmakers'%20Betting%20Odds%20-%20Theory%20and%20Tests.pdf)
  14. [**Optimal Pricing in the Online Betting Market** *by Maurizio Montone (2015)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Optimal%20Pricing%20in%20the%20Online%20Betting%20Market.pdf)
  15. [**Why are Gambling Markets Organised so Differently from Financial Markets?** *by Steven Levitt (2004)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Why%20are%20Gambling%20Markets%20Organised%20so%20Differently%20from%20Financial%20Markets.pdf)
  16. [**Forecasting Accuracy and Line Changes in the NFL and College Football Betting Markets** *by Steven Xu (2013)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Forecasting%20Accuracy%20and%20Line%20Changes%20in%20the%20NFL%20and%20College%20Football%20Betting%20Markets.pdf)
  17. [**The Forecast Ability of the Dispersion of Bookmaker Odds** *by Kwinten Derave (2013-2014)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/The%20Forecast%20Ability%20of%20the%20Dispersion%20of%20Bookmaker%20Odds.pdf)
  18. [**The Stocks at Stake: Return and Risk in Socially Responsible Investment** *by Galema, Plantinga and Scholtens (2008)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/The%20Stocks%20at%20Stake%20-%20Return%20and%20Risk%20in%20Socially%20Responsible%20Investment.pdf)
  19. [**A Comparison of the Forecast Accuracy of Prediction Markets, Betting Odds and Tipsters** *by Martin Spann and Bernd Skiera (2009)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/A%20Comparison%20of%20the%20Forecast%20Accuracy%20of%20Prediction%20Markets%20Betting%20Odds%20and%20Tipsters.pdf)
  20. [**Efficiency of the Market for Racetrack Betting** *by Donald Hausch, William Ziemba and Mark Rubinstein (1981)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Efficiency%20of%20the%20Market%20for%20Racetrack%20Betting.pdf)
  21. [**Betting Market Efficient at Premiere Racetracks** *by Marshall Gramm (2011)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Betting%20Market%20Efficient%20at%20Premiere%20Racetracks.pdf)
  22. [**Late Money and Betting Market Efficiency: Evidence from Australia** *by Marshall Gramm, Nicholas McKinney and Randall Parker (2012)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Late%20Money%20and%20Betting%20Market%20Efficiency%20-%20Evidence%20from%20Australia.pdf)
  23. [**An introduction to football modelling at Smartodds** *by Robert Johnson (2011)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/An%20Introduction%20to%20Football%20Modelling%20at%20SmartOdds%20(v1).pdf)
  24. [**The Value of Statistical Forecasts in the UK Association Football Betting Market** *by Dixon and Pope (2003)*](https://github.com/scibrokes/odds-modelling-and-testing-inefficiency-of-sports-bookmakers/blob/master/reference/DixonPope2004.pdf)
  25. [**Modelling Association Football Scores and Inefficiencies in the Football Betting Market** *by Dixon & Coles (1996)*](https://github.com/scibrokes/odds-modelling-and-testing-inefficiency-of-sports-bookmakers/blob/master/reference/DixonColes1996.pdf)
  26. [**A New Interpretation of Information Rate** *by John Kelly (1956)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/A%20New%20Interpretation%20of%20Information%20Rate.pdf)
  27. [**Dynamic Modelling and Prediction of English Football League Matches for Betting** *by Crowder, Dixon, Ledford and Robinson (2001)*](https://github.com/scibrokes/odds-modelling-and-testing-inefficiency-of-sports-bookmakers/blob/master/reference/DixonLedfordRobinson2001.pdf)
  28. [**Pattern Discovery in Data Mining Programming Assignment: Frequent Itemset Mining Using Apriori** *by ®γσ, Eng Lian Hu (2016)*](http://rpubs.com/englianhu/pattern-discovery-in-data-mining-assignment1)
  29. [**Efficiency of the Racetrack Betting Market (2008 Preface Edition)** *by Donald Hausch, Victor Lo and William Ziemba (2008)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Efficiency%20of%20the%20Racetrack%20Betting%20Market%20(2008%20Edition).pdf)
  30. [**Racetrack Betting and Consensus of Subjective Probabilities** *by Lawrence Brown and Yi Lin (2002)*](https://github.com/scibrokes/betting-strategy-and-model-validation/blob/master/references/Racetrack%20Betting%20and%20Consensus%20of%20Subjective%20Probabilities.pdf)

####  Reference for technical research on programming and coding portion for the paper.

  1. [**Wrangling F1 Data With R** *by Tony Hirst (2014)*](http://www.r-bloggers.com/wrangling-f1-data-with-r-f1datajunkie-book/)
  2. [**Interactive visualizations with R - a minireview** *by Juuso Parkkinen (2014)*](http://ouzor.github.io/blog/2014/11/21/interactive-visualizations.html)
  3. [**R + htmlwidgets + DT + sparkline** *by Matthew Leonawicz (2015)*](https://blog.snap.uaf.edu/2015/10/01/r-htmlwidgets-dt-sparkline/)
  4. [**Programming Assignment 2 Submission : Data Visualization by University of Illinois at Urbana-Champaign** *by ®γσ, Eng Lian Hu (2016)*](https://beta.rstudioconnect.com/englianhu/Programming-Assignment-2-Submission/#read-data)
  5. [Using Roles via googleVis](https://cran.r-project.org/web/packages/googleVis/vignettes/Using_Roles_via_googleVis.html)
  6. [**Welcome to the Highcharter homepage** *by Joshua Kunst (2016)*](http://jkunst.com/highcharter/index.html)
  7. [**R语言量化投资常用包总结** *by 张丹(2016)*](http://mp.weixin.qq.com/s?__biz=MzA3MTM3NTA5Ng==&mid=2651054987&idx=1&sn=11c6bb68dbb0d77598a1d2459cff6dcf&chksm=84d9c21cb3ae4b0ade8f398760e6414be06c4e9cb69d1389df46e326fd481e3320c9ffb92319&scene=0#wechat_redirect)

**Powered by - Copyright® Intellectual Property Rights of <img src='figure/oda-army.jpg' width='24'> [Scibrokes®](http://www.scibrokes.com)個人の経営企業**
