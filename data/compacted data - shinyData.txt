## SHORT NOTES
## 
## In order to ease the read source files, kindly load data source by refer to below 
## section named chunk `load-data` which is execution of both `read-data-summary-table` 
## and scrap-data. The source file saved in folder `regressionApps` named `shinyData.RData`.

## ------------- load-data --------------------------------------
```{r load-data, echo = FALSE, results = 'asis'}
## Load saved dataset to save the loading time.
## directly load the dataset from running chunk `read-data-summary-table` and also chunk `scrap-data`. The spboData for filtering leagues and matches scores purpose.
load('./regressionApps/shinyData.RData')
```

## Below are the steps to get the result of above dataset.

## ------------- read-data-summary-table --------------------------------------
```{r read-data-summary-table, eval = FALSE, echo = FALSE, results = 'asis'}
## Setup Options, Loading Required Libraries and Preparing Environment
## Loading the packages and setting adjustment again due to unable find the functions
suppressMessages(library('utils'))
suppressMessages(source('function/libs.R'))
suppressMessages(require('DT', quietly = TRUE))

## Read the data
## Refer to **Testing efficiency of coding.Rmd** at chunk `get-data-summary-table-2.1`
years <- seq(2011, 2015)

## Here I take the majority leagues setting profile which are "league-10-12"
## fMYPriceB = Back with vigorish price; fMYPriceL = Lay with vigorish price
## Here we term as Fair Odds
lProfile <- c(AH = 0.10, OU = 0.12)

mbase <- readfirmData(years = years, pth = './data/') %>% arrfirmData(lProfile = lProfile)

## In order to analyse the AHOU, here I need to filter out all soccer matches other than AHOU. (For example : Corners, Total League Goals etc.)
## the stakes amount display as $1 = $10,000
#'@ mbase$datasets[!(mbase$datasets$Home %in% mbase$corners)|!(mbase$datasets$Away %in% mbase$corners),]
dat <- mbase$datasets %>% filter((!Home %in% mbase$others)|(!Away %in% mbase$others)) %>% mutate(Stakes = Stakes/10000, Return = Return/10000, PL = PL/10000)

rm(years, readfirmData, arrfirmData)
rm(mbase) ## We need to scrap the livescore data based on the raw data mbase without filter, but this is not the point in this research paper.
```

## ------------- scrap-data --------------------------------------
```{r scrap-data, eval = FALSE, echo = FALSE, results = 'asis'}
## Scrape the leagues and also overrounds which provides by a sportsbookmaker named Firm B
#'@ lnk <- 'http://data.nowgoal.com/history/handicap.htm'
## Above website provides odds price history but sendkeyElements cannot work in RSelenium, will follow-up
## https://github.com/ropensci/RSelenium/issues/55
## Therefore scrape spbo link to know the league of matches

## Besides, need to scrap the final-scores / half-time scores / result of soccer matches
#'@ dateID <- sort(unique(mbase$datasets$Date)); spboDate <- gsub('-','',dateID)
#'@ lnk <- paste0('http://www8.spbo.com/history.plex?day=', spboDate, '&l=en')
## kick-off time(GMT+8) - 12hrs since livescore website start count a day from 12pm(GMT+8)
dateID <- as.Date(sort(unique(dat$Date) - hm('12:00'))); spboDate <- gsub('-', '', dateID)

## Due to the scrapSPBO function scrapped unmatched data, example lnk[827],
##  therefore I rewrite the function as scrapSPBO2
#'@ suppressAll(source('function/scrapSPBO2.R'))
#'@ scrapSPBO2(lnk = lnk, dateID = dateID, path = 'livescore', parallel = TRUE)

## Read spbo livescore datasets.
spboData <- readSPBO(dateID = dateID, parallel = FALSE)$data

## Apply stringdist() to 'exactly matching' and 'approximate matching' team names
#'@ method <- c('osa', 'lv', 'dl', 'hamming', 'lcs', 'qgram', 'cosine', 'jaccard', 'jw', 'soundex')
#'@ source(paste0(getwd(),'/function/arrTeamID.R'))
#'@ tmID <- arrTeamID(mbase, spboData, parallel = FALSE)
tmIDdata <- read.csv('./data/teamID.csv', header = TRUE, sep = ',') %>% mutate_each(funs(as.character)) %>% data.frame %>% tbl_df %>% filter(spbo != 'Kuban Krasnodar')
spboData %<>% filter((Home %in% tmIDdata$spbo)|(Away %in% tmIDdata$spbo))

## filter the bet slips with spbo live scores matches.
#'@ dat %<>% filter(as.Date(DateUK) %in% as.Date(spboData$DateUK), Home %in% tmIDdata$teamID, Away %in% tmIDdata$teamID)

#'@ spboData %<>% filter(as.Date(DateUK) %in% as.Date(dat$DateUK), Home %in% tmIDdata$teamID, Away %in% tmIDdata$teamID)

tmIDdata %<>% mutate(Home = factor(teamID), Away = factor(teamID), spboHome = factor(spbo), spboAway = factor(spbo)) %>% .[-c(1:3)]

dat <- join_all(list(dat, tmIDdata[c(1, 3)]), by = c('Home'), type = 'inner') %>% tbl_df
dat <- join_all(list(dat, tmIDdata[c(2, 4)]), by = c('Away'), type = 'inner') %>% tbl_df

names(spboData)[names(spboData) == 'Home'] <- 'spboHome'
names(spboData)[names(spboData) == 'Away'] <- 'spboAway'
names(spboData)[names(spboData) == 'DateUK'] <- 'spboDateUK'
names(spboData)[names(spboData) == 'Time'] <- 'spboTime'
dat <- dat[order(dat$Date, dat$Time, decreasing = FALSE), ]
#'@ names(dat)
#   [1] c("No", "Sess", "Month", "Day", "DateUK", "Date", "Time", "Home", "Away", "Selection", "HCap", "EUPrice", "HKPrice", "Stakes", "CurScore", "Mins", "Result", "Return", "PL", "Rebates", "Picked", "AHOU", "fMYPriceB", "fMYPriceL", "pHKRange", "fHKPriceL", "pMYRange", "pHKRange2", "pMYRange2", "InPlay", "Mins2", "InPlay2", "ipRange", "HG", "AG", "FHFTET", "Picked2", "ipHCap", "CurScore2", "netProbB", "netProbL", "favNetProb", "undNetProb", "spboHome", "spboAway")

## join data to get a completed data with leagues, final scores in order to run the simulation in staking and Poisson section.
#'@ dat1 <- join_all(list(dat, spboData), by = c('Date', 'spboHome', 'spboAway'), type = 'full') %>% tbl_df %>% na.omit ## Due to join_all() will cause the Time variable became '0' numeric value. Therefore use merge instead.
dat <- merge(dat, spboData, by = c('Date', 'spboHome', 'spboAway')) %>% tbl_df

#'@ names(dat)
#   [1] c("Date", "spboHome", "spboAway", "No.x", "Sess", "Month", "Day", "DateUK", "Time", "Home", "Away", "Selection", "HCap", "EUPrice", "HKPrice", "Stakes", "CurScore", "Mins", "Result", "Return", "PL", "Rebates", "Picked", "AHOU", "fMYPriceB", "fMYPriceL", "pHKRange", "fHKPriceL", "pMYRange", "pHKRange2", "pMYRange2", "InPlay", "Mins2", "InPlay2", "ipRange", "HG", "AG", "FHFTET", "Picked2", "ipHCap", "CurScore2", "netProbB", "netProbL", "favNetProb", "undNetProb", "No.y", "X", "matchID", "LeagueColor", "League", "spboDateUK", "spboTime", "Finished", "FTHG", "FTAG", "HTHG", "HTAG", "H.Card", "A.Card", "HT.matchID", "HT.graph1", "HT.graph2")
## Due to the daily financial settlement of Asian bookmakers based on 12.00PM (GMT + 8), therefore I just leave the merged data name alignment above to ease for refer the time and score.

## saveImage after filter to ease the whole research and efficiency of read data.
#'@ save.image("./regressionApps/shinyData.RData")

rm(dateID, spboDate, scrapSPBO, readSPBO, tmIDdata, spboData)
```
